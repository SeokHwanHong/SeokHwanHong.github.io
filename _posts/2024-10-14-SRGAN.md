---
layout: single        # 문서 형식
title: Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network (2017) # 제목
categories: Super-Resolution    # 카테고리
tag: [DL, Image, Generative]
author_profile: false # 홈페이지 프로필이 다른 페이지에도 뜨는지 여부
sidebar:              # 페이지 왼쪽에 카테고리 지정
    nav: "counts"       # sidebar의 주소 지정
#search: false # 블로그 내 검색 비활성화
use_math: true
---
# Keywords
GAN, Super-Resolution

# 1. Method
#### - Notation
$$I^{LR} \in \mathbb{R}^{W \times H \times C} $$ : 고해상도에서 가우시안 필터를 적용해 얻은 저해상도 이미지

$$I^{HR} \in \mathbb{R}^{ r W \times r H \times C} $$ : 고해상도 이미지

$r$ : downsampling factor

$G_{\theta_{G}}$ : 주어진 저해상도와 고해상도 이미지 짝에 대한 SR 생성함수, feed-forward CNN 으로 구성

$\theta_{G} = \{ W_{1:L} ; b_{1:L} \}$ : L 번째 층의 가중치와 편향, 손실함수 최적화 중 계산

$l^{SR}$ : 인지적 손실함수

#### - Goals

$$
\begin{split}
    \hat{\theta}_G = argmin_{\theta_G} \frac{1}{N} \sum_{n=1}^{N} l^{SR} (G_{\theta_G}(I_n^{SR}), I_n^{HR})
\end{split}
$$


## 2.1. Adversarial Network Architecture
<p align="center">
  <a href="#">
    <img src="/images/SRGAN/figure4.jpg" height="350" />
  </a>
  <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  <b>[ Figure 1 : SRGAN Overall Architecture ]</b> 
</p>


#### - Adversarial min-max Problem

$$
\begin{split}
    \min_{\theta_G} \max_{\theta_D} \mathbb{E}_{I^{HR} \sim p_{train}(I^{HR})} \left[ \log D_{\theta_D} (I^{HR})] + \mathbb{E}_{I^{LR} \sim p_{G}(I^{LR})} [\log (1 - D_{\theta_D} (G_{\theta_G}(I^{LR}))) \right]
\end{split}
$$

$D$ : 실제와 초해상화 이미지를 구별하기 위해 훈련되는 미분가능한 판별 신경망

$G$ : 실제와 초해상화 이미지를 최대한 유사하게 생성해 $D$ 를 속이는 생성 신경망

기존 SR 방법들은 MSE와 같은 픽셀 단위의 오류측정을 최소화하는 반면 SRGAN에서는 인지적 방법을 통해 오류를 최소화하고자 한다.


## 2.2. Perceptual Loss Function

$$
\begin{split}
    l^{SR} = \underbrace {\underbrace{l_X^{SR}}_{content \: loss} + \underbrace{10^{-3} l_{Gen}^{SR}}_{adversairal \: loss}} _{perceptual \: loss \: (for VGG \: based \: content \: loss)}
\end{split}
$$

#### - Content Loss
**1. 픽셀단위 MSE 손실함수**

$$
\begin{split}
    l^{SR}_{MSE} = \frac{1}{r^2WH} \sum_{x=1}^{rW} \sum_{y=1}^{rH} (I_{x,y}^{HR} - G_{\theta_G}(I^{LR})_{x,y})^2
\end{split}
$$

기존 SR 모델들이 가장 많이 사용하는 손실함수이다. 주로 high frequency 내용들을 잘 반영하지 못해 결과물들이 뭉게져 나오기도 한다.


**2. VGG 손실함수**

본 논문에서는 VGG19를 기반으로 한 손실함수를 제안한다. 

$$
\begin{split}
    l_{VGG /i,j}^{SR} = \frac{1}{W_{i,j} H_{i,j}} \sum_{x=1}^{W{i,j}} \sum_{y=1}^{H_{i,j}} (\phi_{i,j} (I^{HR})_{x,y} - \phi_{i,j} (G_{\theta_G}(I^{LR}))_{x,y})^2
\end{split}
$$

여기서 $\phi_{i,j}$ 는 VGG19 i번째 maxpooling 층 이전의 j번째 합성곱 층에서 얻은 feature map 이다. 이 손실함수는 $G_{\theta_G}(I^{LR})$ 로 만들어진 이미지와 실제 이미지 $I^{HR}$ 간 유클리디안 거리를 계산한다.


#### - Adversarial Loss
기존 GAN 의 손실함수에서 인지적 손실을 추가하였다. 

$$
\begin{split}
    l_{Gen}^{SR} = \sum_{n=1}^N - \log D_{\theta_D}(G_{\theta_G}(I^{LR}))
\end{split}
$$

여기서 $\log D_{\theta_D}(G_{\theta_G}(I^{LR}))$ 는 생성한 이미지 $(G_{\theta_G}(I^{LR}))$ 가 실제 이미지인지에 대한 확률이다. 따라서 더 좋은 성능을 내기 위해서는 $- \log D_{\theta_D}(G_{\theta_G}(I^{LR}))$ 을 최소화하는 것이 중요하다. 


