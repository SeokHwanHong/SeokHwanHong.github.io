---
layout: single        # 문서 형식
title: Image Super-Resolution using Deep Convolution Networks (2016) # 제목
categories: Super-Resolution    # 카테고리
tag: [DL, Image, Generative]
author_profile: false # 홈페이지 프로필이 다른 페이지에도 뜨는지 여부
sidebar:              # 페이지 왼쪽에 카테고리 지정
    nav: "docs"       # sidebar의 주소 지정
#search: false # 블로그 내 검색 비활성화
use_math: true
---
# Keywords
Convolution Networks, Super-Resolution

# 1. Convolutional Neural Networks for Super-Resolution
## 1.1. Formulation
단일 저해상도 이미지에 대해 bicubic interpolation 을 이용해 원하는 크기로 조정하는 것이 유일한 전처리이다.

$\mathbf{Y}$ : bicubic interpolation 이 적용된 저해상도 이미지
$F(\cdot)$ : 해상도를 증가시키는 모델 
$\mathbf{X}$ : $\mathbf{Y}$ 와 크기가 동일한 실제 고해상도 이미지

모형의 구조는 다음과 같다.

<figure style="text-align: center; display: inline-block; width: 100%;">
    <img src = "/images/SRCNN/figure2.jpg" height = 250>    
    <figcaption style="display: block; width: 100%; text-align: center;">[ Figure 1 : SRCNN Model Architecture ]</figcaption>
</figure>


#### 1.1.1. Patch Extraction & Representation

기존 이미지 복원에서 주로 사용되는 전략은 패치를 추출해 PCA, DCT, Haar 등의 사전학습된 기저 집합으로 표현하는 것이다. 저자는 추출한 각 기저들의 최적화 과정을 신경망 최적화에 대입하는데, 이는 신경망이 최적의 기저를 자동으로 학습하도록 구성하는 것이다. 따라서 첫 번째 층은 다음과 같은 연산 $F_1$ 으로 표현된다.

$$
F_1 (\mathbf{Y}) = \max (0, W_1 * \mathbf{Y} + B_1), 
$$

여기서 $B_1$ 은 $n_1$ 차원인 편향을, * 은 합성곱 연산을 의미한다. $W_1$ 은 필터를 의미하며, 입력 이미지의 채널 수 $c$ 와 필터의 한 변의 크기 $f_1$ 에 대해, $c \times f_1 \times f_1$ 의 크기를 가진 필터 $n_1$ 개로 구성된다. 따라서 $F_1$ 은 특징맵이 $ n_1 $ 개이며 이에 대해 ReLU 를 적용한다. 

#### 1.1.2. Non-Linear Mapping

첫 번째 층에서 추출한 특징맵 $n_1$ 개 ($n_1$ 차원 벡터)를 $n_2$ 차원 벡터로 mapping 한다. 이는 공간적 크기가 $1 \times 1$ 인 필터 $n_2$ 개를 적용하는 것과 동일하다. $1 \times 1$ 대신 $3 \times 3$ 이나 $5 \times 5$ 를 사용하는 경우, 입력 이미지에 대한 patch 가 아닌 첫 번째 층에서 추출한 특징 맵에 대한 patch 로 비선형 mapping 이 이루어진다. 두 번째 층의 연산은 다음과 같다.

$$
F_2 (\mathbf{Y}) = \max (0, W_2 * F_1(\mathbf{Y}) + B_2), 
$$

여기서 $B_2$ 는 $n_2$ 차원 벡터, $W_2$ 는 크기가 $n_2 \times f_2 \times f_2$ 인 필터 $n_2$ 개다. 각각의 결과 벡터는 복원에 사용될 고해상도 패치들이다. 합성곱 층을 추가해 비선형성을 증가시킬 수 있다. 하지만 이는 모형의 복잡도를 증가시키며 더 많은 학습시간이 필요하다. 

#### 1.1.3. Reconstruction

세 번째 층은 겹치는 패치들에 대해 평균과 같은 조합을 통해 고해상도 이미지를 생성한다. 이를 위해 다음과 같은 합성곱 층을 정의한다.

$$
F (\mathbf{Y}) = W_3 * F_2(\mathbf{Y}) + B_3 
$$

여기서 $B_3$ 는 $c$ 차원 벡터, $W_3$ 는 크기가 $n_2 \times f_3 \times f_3$ 인 필터 $c$ 개다. 필터가 이미지 영역에 존재하는 경우, 각 패치를 단순히 재구성할 수 있는 형태로 표현해 필터 내 각 패치가 겹치는 부분에 대해 평균을 계산한다. 이미지가 아닌 다른 영역에 존재하는 경우, 이미지 영역으로 변환 후 평균을 계산한다.
이 때, 모든 filtering 가중치들과 편향들은 훈련 데이터에 맞춰가며 최적화가 진행된다. 

## 1.2. Relationship to Sparse-Coding-Based Methods
#### 1.2.1. Sparse-Coding-Based Super-Resolution
Sparse-Coding-Based Super-Resolution 은 저해상도 이미지를 고해상도로 변환하기 위해 sparse representation 을 활용하는 방법이다. 이는 이미지를 구성하는 패치들에 대해, 각 패치를 적은 수의 특징 벡터로 표현할 수 있다는 아이디어로 시작한다. 특히, 저해상도와 고해상도 이미지 간 관계를 학습해 패치를 기반으로 복원을 수행하는 경우 효과적이다. 다음과 같은 절차로 초해상화를 수행한다.

1. Dictionary Learning (사전 학습)
사전(dictionary)이란 고해상도와 저해상도 이미지 패치들의 집합을 통해 학습된 일종의 데이터 베이스로, 각 패치를 압축적이고 희소한 방식으로 표현할 수 있게 설계된 요소들의 모음이다. 사전 학습 단계에서 이 이미지 패치 쌍을 사용해 고해상도와 저해상도 사전을 학습한다. 이 때, 두 패치가 서로의 희소표현을 공유하도록 설계한다.   

2. Sparse Coding (희소 코딩)
저해상도 이미지가 주어지면, 이를 작은 패치로 나누어 각 패치를 저해상도 사전의 희소 표현으로 나타낸다. 이는 특정 저해상도 패치를 고해상도 사전에 있는 패치들의 조합으로 근사하는 과정이다. 이 과정에서 희소 코딩 알고리즘이 적용되어, 저해상도 패치를 적은 수의 사전 원소로 효율적으로 표현한다. 

3. Reconstruction (고해상도 패치 복원)
저해상도 패치의 희소 표현을 바탕으로 대응하는 고해상도 패치를 생성한다. 저해상도 이미지의 각 패치를 재구성해 고해상도 사전과 연결함으로써 저해상도 이미지의 해상도를 높이는 작업을 수행한다. 이러한 패치들은 블록과 같이 배치되고, 블록 간 경계를 매끄럽게 연결해 최종적으로 고해상도 이미지를 완성한다.


#### 1.2.2. Sparse-Coding-Based Methods

Sparse-Coding 에 기반한 방법은 다음 그림과 같은 프레임워크로 진행한다.

<figure style="text-align: center; display: inline-block; width: 100%;">
    <img src = "/images/SRCNN/figure3.jpg" height = 250>    
    <figcaption style="display: block; width: 100%; text-align: center;">[ Figure 2 : An Illustration of Sparse-Based-Coding ]</figcaption>
</figure>

크기가 $f_1 \times f_1$ 인 저해상도 패치를 입력 사전에 정의된 저해상도 사전을 사용해 이미지에서 추출해 $n_1$ 차원의 벡터(희소 코드)로 표현한다. 여기에 사용한 희소 코드를 비선형적 매핑을 통해 고해상도 사전에도 적용함으로써 고해상도 패치를 $n_2$ 차원의 벡터로 복원한다. SRCNN 의 핵심 아이디어는 위 과정에서 복잡한 사전 학습 및 맵핑 과정을 CNN 층으로 통합해 학습함으로써 계산 효율성을 높이면서도 sparse-coding 기반의 구조적 특징을 유지한다. 또한, CNN을 통해 학습이 자동화되고 성능이 개선되는 효과를 얻는다.

#### 1.2.3. Why SRCNN is end-to-end mapping?
위의 figure들에서 확인할 수 있듯이, SRCNN 은 입력된 저해상도 이미지가 신경망을 통과하면서 별도의 중간 단계나 독립적인 사전 학습 없이 최종 고해상도 이미지로 직접 변환되기 때문이다. 기존의 sparse-coding 기반 방법들은 저해상도 이미지의 각 패치를 사전에 학습된 기저 벡터로 표현하고, 이를 매핑한 뒤 고해상도 패치를 재구성하는 단계가 분리되는 복잡한 과정을 거친다. 그러나 SRCNN 은 CNN 구조를 이용함으로써 이 복잡한 과정을 단일 신경망으로 통합해 수행한다. 따라서 SRCNN 은  다음과 같은 장점들을 갖는다.

1. 효율성
이미지의 해상도에 따른 변환 과정을 신경망이 학습함으로써, 중간 단계에서 발생할 수 있는 정보 손실이나 왜곡을 감소

2. 효율성
sparse-coding 에서 요구되는 사전 학습이나 복잡한 최적화 과정 없이 CNN 의 파라미터들만 학습하기 때문에 계산 비용이 감소하고 속도가 증가

3. 성능 개선
신경망이 전체 변환 과정을 최적화하여 더욱 정교한 초해상도 결과를 획득




# 2. Training

## 2.1. Notation
$F$ : end-to-end 매핑 함수
$\Theta = \{ W_1, W_2, W_3, B_1, B_2, B_3 \}$ : 신경망의 파라미터
$\mathbf{Y}$ : 저해상도 이미지
$\mathbf{X}$ : 기존 고해상도 이미지
$F(\mathbf{Y}; \Theta)$ : 복원된 이미지

## 2.2. Loss function

손실 함수는 Mean Squared Error 의 형태로 다음과 같이 정의된다.

$$
L(\Theta) = \frac{1}{n} \sum_{i=1}^n ||F(\mathbf{Y}_i ; \Theta) - \mathbf{X}_i||^2
$$

만약 손실 함수가 미분이 가능하다면, 합성곱 신경망은 다른 종류의 손실 함수를 사용할 수도 있다. 즉, 학습 과정에서 더 좋은 품질을 목표로 하는 지표가 있다면, 신경망은 그 지표에 맞게 변경할 수 있다.

#### - Minimizing
표준적인 역전파와 SGD 를 이용해 손실함수를 최소로 만든다. 본 논문에서는 가중차 행렬을 다음과 같이 갱신한다.

$$
\Delta_{i+1} = 0.9 \cdot \Delta_{i} + \eta \cdot \frac{\partial L}{\partial W_i^l}, \quad W_{i+1}^l = W_{i}^l + \Delta_{i+1}
$$

여기서 $l \in \{1,2,3\}$ 은 층에 대한 인덱스, $i$ 는 반복 순서, $\eta$ 는 학습률, 그리고 $\frac{\partial L}{\partial W_i^l}$ 은 층별 미분계수를 의미한다. 각 층의 필터 가중치는 평균이 0, 표준편차가 0.001, 편향이 0인 정규분포에서 무작위로 추출한 값으로 초기화된다. 또한, 첫 두 층에서는 학습률이 $10^{-4}$, 마지막 층은 $10^{-5}$ 로 조정한다. 이와 같이 구성한 이유는 신경망의 손실 함수가 수렴하기 위해서 마지막 층의 학습률이 더 작아야하기 때문이다. 

## 2.3. Training Details
1. 학습 이미지로부터 임의로 샘플링해 크기가 $f_{sub} \times f_{sub} \times c$ 인 기준 $\{\mathbf{X}_i\}$ sub-image 집합을 구성한다. 이는 패치처럼 겹치는 부분이 존재하거나 후처리 등을 하는 것이 아닌 사이즈가 더 작은 이미지로 간주한다. 왜냐하면 더 넓은 맥락 학습, 경계 문제 완화, 다양한 패턴 학습 가능, 효율적 데이터 활용과 같은 장점이 있기 때문이다.

2. border effect 를 방지하기 위해 padding 을 사용하지 않고 신경망이 크기가 $((f_{sub} - f_1 - f_2 - f_3 + 3)^2 \times c)$ 인 이미지를 결과로 출력한다. 

3. MSE 손실 함수는 sub-image $\mathbf{X}_i$ 와 신경망의 결과로만 계산한다. 

4. $cuda-convnet$ 패키지와 $Caffe$ 패키지를 사용하였다. 




# 3. Experiments
## 3.1. Data Set Scale
1. 작은 훈련 데이터 셋
약 91장으로 구성, $f_{sub}$ = 33 (큰 데이터 셋도 동일), 24,800 개의 sub-image 로 분해(기존 이미지에서 stride=14 로 분해)

2. 큰 훈련 데이터 셋
ILSVRC 2013 ImageNet detection training partition 에서 사용한 데이터 395,909 장으로 구성, $f_1 = 9, f_2 = 1,f_3 = 5, n_1 = 64, n_2 = 32$

3. 검증 데이터 셋
$Set5$ 사용

4. 기타
upscaling factor = 3

5. 결과

<figure style="text-align: center; display: inline-block; width: 100%;">
    <img src = "/images/SRCNN/figure4.jpg" height = 200>    
    <figcaption style="display: block; width: 100%; text-align: center;">[ Figure 3 : The Test Convergence Curve of SRCNN & The Result of DNC ]</figcaption>
</figure>

모델이 작은 데이터 셋에서 이미지의 특징들을 충분히 포착했기 때문에 데이터 셋에 크기에 따른 성능 차이는 크지 않은 것으로 보인다. 

## 3.2. Model and Performance Trade-offs
#### - Filter Number

신경망 너비, 필터 수 등을 조절해 성능을 확인

1. 기본 설정
$n_1 = 64, n_2 = 32$

2. large network
$n_1 = 128, n_2 = 64$

3. smaller network
$n_1 = 32, n_2 = 16$

4. 결과

<figure style="text-align: center; display: inline-block; width: 100%;">
    <img src = "/images/SRCNN/table1.jpg" height = 90>    
    <figcaption style="display: block; width: 100%; text-align: center;">[ Table 1 : The Results of Using Different Filter Numbers in SRCNN ]</figcaption>
</figure>

크기에 대한 성능 차이는 크지 않았고, 속도는 확연히 차이가 나는 것을 확인할 수 있다.

#### - Filter Size
필터 크기에 따른 신경망의 성능 차이를 확인

1. 기본 설정
$f_1 = 9, f_2 = 1, f_3 = 5 \rightarrow 9-1-5$

2. 다른 설정
9-5-5, 9-3-5, 11-1-7 등 사용

3. 결과

<figure style="text-align: center; display: inline-block; width: 100%;">
    <img src = "/images/SRCNN/figure7.jpg" height = 200>    
    <figcaption style="display: block; width: 100%; text-align: center;">[ Figure 4 : A Larger Filter Size Leads to Betters Results ]</figcaption>
</figure>

필터 크기를 증가시킴에 따라 성능이 더 좋아지는 것을 확인할 수 있다. 그러나 9-5-5 의 복잡도는 9-3-3 의 약 2배 가량 크기때문에, 적당한 필터 크기를 설정하는 것이 더 좋은 것으로 보인다.

#### - Number of layers
1. $n_{22} = 16, f_{22} = 1$ 
크기가 $n_{22} = 16, f_{22} = 1$ 인 또다른 비선형 맵핑을 추가해 모델 구조를 더 깊게 구성하였다. 따라서 모델 구조가 각각 9-1-1-5, 9-3-1-5, 9-5-1-5 이고, 각각을 9-1-5, 9-3-5, 9-5-5 와 비교한다.

<figure style="text-align: center; display: inline-block; width: 100%;">
    <img src = "/images/SRCNN/figure8.jpg" height = 500>    
    <figcaption style="display: block; width: 100%; text-align: center;">[ Figure 5 : Comparison between Three-Layer and Four-Layer Networks ]</figcaption>
</figure>

2. $n_{22} = 32, f_{22} = 3$ 
크기가 $n_{22} = 32, f_{22} = 3$ 이외에도 더 깊은 비선형 맵핑을 추가해 비교를 진행하였다.

<figure style="text-align: center; display: inline-block; width: 100%;">
    <img src = "/images/SRCNN/figure9.jpg" height = 350>    
    <figcaption style="display: block; width: 100%; text-align: center;">[ Figure 6 : Comparison between Three-Layer and Deeper Four-Layer Networks ]</figcaption>
</figure>

충분한 시간동안 훈련했음에도 불구하고 세 실험에서 모두 3층으로 구성된 신경망이 대체로 수렴속도가 빠른 것을 확인할 수 있다. 즉, 신경망의 깊이가 깊은 것과 수렴속도, 성능 등은 항상 비례관계는 아니라는 것을 알 수 있다.


## 3.3. Color Channles 
컬러 이미지가 아닌 YCbCr 공간으로 변환해 Y (Luminance, 밝기(휘도)) 채널에만 초해상화 알고리즘을 적용한다. 이 때 Cb (Chrominance-Blue, 파란색 성분을 나타내는 색차 채널)와 Cr (Chrominance-Red, 빨간색 성분을 나타내는 색차 채널) 은 bicubic 보간법으로 업스캐일링을 진행한다.

#### - Details
학습 데이터 셋 : 91-image dataset
평가 데이터 셋 : $Set5$
신경망 구성 : $c=3, f_1 = 9, f_2 = 1, f_3 = 5, n_1 = 64, n_2 = 32$
upscaling factor = 3

#### - Results

<figure style="text-align: center; display: inline-block; width: 100%;">
    <img src = "/images/SRCNN/table5.jpg" height = 200>    
    <figcaption style="display: block; width: 100%; text-align: center;">[ Table 2 : Average PSNR of different Channels & Training Strategies on the Set5 ]</figcaption>
</figure>

$\mathbf{Y \: pre-train}$ : Y 의 변화에 따른 성능 차이를 확인하기 위해 신경망을 사전학습할 때 Y 채널의 MSE 만을 손실함수로 사용한다.

위 결과를 통해 YCrCb 색상 공간을 사용함으로써 필요한 연산량이 줄어들고, 결과 이미지의 품질이 정량적 지표에서도 높은 성능을 보이는 것을 알 수 있다. 따라서 위 실험들에서 SRCNN 은 컬러 이미지에서도 효율적이고 우수한 초해상화 성능을 보임을 알 수 있다.