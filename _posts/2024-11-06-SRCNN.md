---
layout: single        # 문서 형식
title: Image Super-Resolution using Deep Convolution Networks (2016) # 제목
categories: Super-Resolution    # 카테고리
tag: [DL, Image, Generative]
author_profile: false # 홈페이지 프로필이 다른 페이지에도 뜨는지 여부
sidebar:              # 페이지 왼쪽에 카테고리 지정
    nav: "counts"       # sidebar의 주소 지정
#search: false # 블로그 내 검색 비활성화
use_math: true
---
# Keywords
Convolution Networks, Super-Resolution

# 1. Convolutional Neural Networks for Super-Resolution
## 1.1. Formulation
단일 저해상도 이미지에 대해 bicubic interpolation 을 이용해 원하는 크기로 조정하는 것이 유일한 전처리이다.

$$\mathbf{Y}$$ : bicubic interpolation 이 적용된 저해상도 이미지

$$F(\cdot)$$ : 해상도를 증가시키는 모델 
$
$\mathbf{X}$$ : $\mathbf{Y}$ 와 크기가 동일한 실제 고해상도 이미지

모형의 구조는 다음과 같다.

<p align="center">
  <a href="#">
    <img src="/images/SRCNN/figure2.jpg" height="250" />
  </a>
  <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  <b>[ Figure 1 : SRCNN Model Architecture ]</b> 
</p>

#### 1.1.1. Patch Extraction & Representation

기존 이미지 복원에서 주로 사용되는 전략은 패치를 추출해 PCA, DCT, Haar 등의 사전학습된 기저 집합으로 표현하는 것이다. 저자는 추출한 각 기저들의 최적화 과정을 신경망 최적화에 대입하는데, 이는 신경망이 최적의 기저를 자동으로 학습하도록 구성하는 것이다. 따라서 첫 번째 층은 다음과 같은 연산 $F_1$ 으로 표현된다.

$$
\begin{split}
    F_1 (\mathbf{Y}) = \max (0, W_1 * \mathbf{Y} + B_1), 
\end{split}
$$

여기서 $$B_1 \text{은} n_1$$ 차원인 편향을, * 은 합성곱 연산을 의미한다. $$W_1$$ 은 필터를 의미하며, 입력 이미지의 채널 수 $$c$$ 와 필터의 한 변의 크기 $$f_1$$ 에 대해, $$c \times f_1 \times f_1$$ 의 크기를 가진 필터 $$n_1$$ 개로 구성된다. 따라서 $$F_1$$ 은 특징맵이 $$ n_1$$ 개이며 이에 대해 ReLU 를 적용한다. 



#### 1.1.2. Non-Linear Mapping

첫 번째 층에서 추출한 특징맵 $$n_1 \text{은} (n_1 \text{차원 벡터})$$ 를 $$n_2$$ 차원 벡터로 mapping 한다. 이는 공간적 크기가 $$1 \times 1$$ 인 필터 $$n_2$$ 개를 적용하는 것과 동일하다. $$1 \times 1 \text{대신} 3 \times 3 \text{이나} 5 \times 5$$ 를 사용하는 경우, 입력 이미지에 대한 patch 가 아닌 첫 번째 층에서 추출한 특징 맵에 대한 patch 로 비선형 mapping 이 이루어진다. 두 번째 층의 연산은 다음과 같다.

$$
\begin{split}
    F_2 (\mathbf{Y}) = \max (0, W_2 * F_1(\mathbf{Y}) + B_2), 
\end{split}
$$

여기서 $$B_2 \text{는} n_2$$ 차원 벡터, $$W_2$$ 는 크기가 $$n_2 \times f_2 \times f_2$$ 인 필터 $$n_2$$ 개다. 각각의 결과 벡터는 복원에 사용될 고해상도 패치들이다. 합성곱 층을 추가해 비선형성을 증가시킬 수 있다. 하지만 이는 모형의 복잡도를 증가시키며 더 많은 학습시간이 필요하다. 



#### 1.1.3. Reconstruction

세 번째 층은 겹치는 패치들에 대해 평균과 같은 조합을 통해 고해상도 이미지를 생성한다. 이를 위해 다음과 같은 합성곱 층을 정의한다.

$$
\begin{split}
    F (\mathbf{Y}) = W_3 * F_2(\mathbf{Y}) + B_3 
\end{split}
$$

여기서 $$B_3 \text{는} c$$ 차원 벡터, $$W_3$$ 는 크기가 $$n_2 \times f_3 \times f_3$$ 인 필터 $$c$$ 개다. 필터가 이미지 영역에 존재하는 경우, 각 패치를 단순히 재구성할 수 있는 형태로 표현해 필터 내 각 패치가 겹치는 부분에 대해 평균을 계산한다. 이미지가 아닌 다른 영역에 존재하는 경우, 이미지 영역으로 변환 후 평균을 계산한다. 이 때, 모든 filtering 가중치들과 편향들은 훈련 데이터에 맞춰가며 최적화가 진행된다. 



## 1.2. Relationship to Sparse-Coding-Based Methods
#### 1.2.1. Sparse-Coding-Based Super-Resolution
Sparse-Coding-Based Super-Resolution 은 저해상도 이미지를 고해상도로 변환하기 위해 sparse representation 을 활용하는 방법이다. 이는 이미지를 구성하는 패치들에 대해, 각 패치를 적은 수의 특징 벡터로 표현할 수 있다는 아이디어로 시작한다. 특히, 저해상도와 고해상도 이미지 간 관계를 학습해 패치를 기반으로 복원을 수행하는 경우 효과적이다. 다음과 같은 절차로 초해상화를 수행한다.

**1. Dictionary Learning (사전 학습)**

사전(dictionary)이란 고해상도와 저해상도 이미지 패치들의 집합을 통해 학습된 일종의 데이터 베이스로, 각 패치를 압축적이고 희소한 방식으로 표현할 수 있게 설계된 요소들의 모음이다. 사전 학습 단계에서 이 이미지 패치 쌍을 사용해 고해상도와 저해상도 사전을 학습한다. 이 때, 두 패치가 서로의 희소표현을 공유하도록 설계한다.   


**2. Sparse Coding (희소 코딩)**

저해상도 이미지가 주어지면, 이를 작은 패치로 나누어 각 패치를 저해상도 사전의 희소 표현으로 나타낸다. 이는 특정 저해상도 패치를 고해상도 사전에 있는 패치들의 조합으로 근사하는 과정이다. 이 과정에서 희소 코딩 알고리즘이 적용되어, 저해상도 패치를 적은 수의 사전 원소로 효율적으로 표현한다. 


**3. Reconstruction (고해상도 패치 복원)**

저해상도 패치의 희소 표현을 바탕으로 대응하는 고해상도 패치를 생성한다. 저해상도 이미지의 각 패치를 재구성해 고해상도 사전과 연결함으로써 저해상도 이미지의 해상도를 높이는 작업을 수행한다. 이러한 패치들은 블록과 같이 배치되고, 블록 간 경계를 매끄럽게 연결해 최종적으로 고해상도 이미지를 완성한다.




#### 1.2.2. Sparse-Coding-Based Methods

Sparse-Coding 에 기반한 방법은 다음 그림과 같은 프레임워크로 진행한다.

<p align="center">
  <a href="#">
    <img src="/images/SRCNN/figure3.jpg" height="250" />
  </a>
  <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  <b>[ Figure 2 : An Illustration of Sparse-Based-Coding ]</b> 
</p>

크기가 $$f_1 \times f_1$$ 인 저해상도 패치를 입력 사전에 정의된 저해상도 사전을 사용해 이미지에서 추출해 $$n_1$$ 차원의 벡터(희소 코드)로 표현한다. 여기에 사용한 희소 코드를 비선형적 매핑을 통해 고해상도 사전에도 적용함으로써 고해상도 패치를 $$n_2$$ 차원의 벡터로 복원한다. SRCNN 의 핵심 아이디어는 위 과정에서 복잡한 사전 학습 및 맵핑 과정을 CNN 층으로 통합해 학습함으로써 계산 효율성을 높이면서도 sparse-coding 기반의 구조적 특징을 유지한다. 또한, CNN을 통해 학습이 자동화되고 성능이 개선되는 효과를 얻는다.

#### 1.2.3. Why SRCNN is end-to-end mapping?
위의 figure들에서 확인할 수 있듯이, SRCNN 은 입력된 저해상도 이미지가 신경망을 통과하면서 별도의 중간 단계나 독립적인 사전 학습 없이 최종 고해상도 이미지로 직접 변환되기 때문이다. 기존의 sparse-coding 기반 방법들은 저해상도 이미지의 각 패치를 사전에 학습된 기저 벡터로 표현하고, 이를 매핑한 뒤 고해상도 패치를 재구성하는 단계가 분리되는 복잡한 과정을 거친다. 그러나 SRCNN 은 CNN 구조를 이용함으로써 이 복잡한 과정을 단일 신경망으로 통합해 수행한다. 따라서 SRCNN 은  다음과 같은 장점들을 갖는다.

**1. 효율성**

이미지의 해상도에 따른 변환 과정을 신경망이 학습함으로써, 중간 단계에서 발생할 수 있는 정보 손실이나 왜곡을 감소


**2. 효율성**

sparse-coding 에서 요구되는 사전 학습이나 복잡한 최적화 과정 없이 CNN 의 파라미터들만 학습하기 때문에 계산 비용이 감소하고 속도가 증가


**3. 성능 개선**

신경망이 전체 변환 과정을 최적화하여 더욱 정교한 초해상도 결과를 획득




# 2. Training

## 2.1. Notation
$F$ : end-to-end 매핑 함수

$$\Theta = \{ W_1, W_2, W_3, B_1, B_2, B_3 \}$$ : 신경망의 파라미터

$$\mathbf{Y}$$ : 저해상도 이미지

$$\mathbf{X}$$ : 기존 고해상도 이미지

$$F(\mathbf{Y}; \Theta)$$ : 복원된 이미지


## 2.2. Loss function

손실 함수는 Mean Squared Error 의 형태로 다음과 같이 정의된다.

$$
\begin{split}
    L(\Theta) = \frac{1}{n} \sum_{i=1}^n \Vert F(\mathbf{Y}_i ; \Theta) - \mathbf{X}_i \Vert^2
\end{split}
$$

만약 손실 함수가 미분이 가능하다면, 합성곱 신경망은 다른 종류의 손실 함수를 사용할 수도 있다. 즉, 학습 과정에서 더 좋은 품질을 목표로 하는 지표가 있다면, 신경망은 그 지표에 맞게 변경할 수 있다.


#### - Minimizing
표준적인 역전파와 SGD 를 이용해 손실함수를 최소로 만든다. 본 논문에서는 가중차 행렬을 다음과 같이 갱신한다.

$$
\begin{split}
    \Delta_{i+1} = 0.9 \cdot \Delta_{i} + \eta \cdot \frac{\partial L}{\partial W_i^l}, \quad W_{i+1}^l = W_{i}^l + \Delta_{i+1}
\end{split}
$$

여기서 $$l \in \{1,2,3\}$$ 은 층에 대한 인덱스, $$i$$ 는 반복 순서, $$\eta$$ 는 학습률, 그리고 $$\frac{\partial L}{\partial W_i^l}$$ 은 층별 미분계수를 의미한다. 각 층의 필터 가중치는 평균이 0, 표준편차가 0.001, 편향이 0인 정규분포에서 무작위로 추출한 값으로 초기화된다. 또한, 첫 두 층에서는 학습률이 $$10^{-4}$$, 마지막 층은 $$10^{-5}$$ 로 조정한다. 이와 같이 구성한 이유는 신경망의 손실 함수가 수렴하기 위해서 마지막 층의 학습률이 더 작아야하기 때문이다. 


## 2.3. Training Details
1. 학습 이미지로부터 임의로 샘플링해 크기가 $$f_{sub} \times f_{sub} \times c$$ 인 기준 $$\{\mathbf{X}_i\}$$ sub-image 집합을 구성한다. 이는 패치처럼 겹치는 부분이 존재하거나 후처리 등을 하는 것이 아닌 사이즈가 더 작은 이미지로 간주한다. 왜냐하면 더 넓은 맥락 학습, 경계 문제 완화, 다양한 패턴 학습 가능, 효율적 데이터 활용과 같은 장점이 있기 때문이다.

2. border effect 를 방지하기 위해 padding 을 사용하지 않고 신경망이 크기가 $$((f_{sub} - f_1 - f_2 - f_3 + 3)^2 \times c)$$ 인 이미지를 결과로 출력한다. 

3. MSE 손실 함수는 sub-image $$\mathbf{X}_i$$ 와 신경망의 결과로만 계산한다. 

4. $$cuda-convnet$$ 패키지와 $$Caffe$$ 패키지를 사용하였다. 




# 3. Experiments
## 3.1. Data Set Scale
**1. 작은 훈련 데이터 셋**

약 91장으로 구성, $f_{sub}$ = 33 (큰 데이터 셋도 동일), 24,800 개의 sub-image 로 분해(기존 이미지에서 stride=14 로 분해)


**2. 큰 훈련 데이터 셋**

ILSVRC 2013 ImageNet detection training partition 에서 사용한 데이터 395,909 장으로 구성, $$f_1 = 9, f_2 = 1,f_3 = 5, n_1 = 64, n_2 = 32$$


**3. 검증 데이터 셋**

$Set5$ 사용


**4. 기타**

upscaling factor = 3


**5. 결과**

<p align="center">
  <a href="#">
    <img src="/images/SRCNN/figure4.jpg" height="200" />
  </a>
  <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  <b>[ Figure 3 : The Test Convergence Curve of SRCNN & The Result of DNC ]</b> 
</p>

모델이 작은 데이터 셋에서 이미지의 특징들을 충분히 포착했기 때문에 데이터 셋에 크기에 따른 성능 차이는 크지 않은 것으로 보인다. 


## 3.2. Model and Performance Trade-offs
#### - Filter Number

신경망 너비, 필터 수 등을 조절해 성능을 확인

**1. 기본 설정**

$$n_1 = 64, n_2 = 32$$


**2. large network**

$$n_1 = 128, n_2 = 64$$


**3. smaller network**

$$n_1 = 32, n_2 = 16$$


**4. 결과**

<p align="center">
  <a href="#">
    <img src="/images/SRCNN/table.jpg" height="90" />
  </a>
  <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  <b>[ Table 1 : The Results of Using Different Filter Numbers in SRCNN ]</b> 
</p>

크기에 대한 성능 차이는 크지 않았고, 속도는 확연히 차이가 나는 것을 확인할 수 있다.

#### - Filter Size
필터 크기에 따른 신경망의 성능 차이를 확인


**1. 기본 설정**

$f_1 = 9, f_2 = 1, f_3 = 5 \rightarrow 9-1-5$


**2. 다른 설정**
9-5-5, 9-3-5, 11-1-7 등 사용


**3. 결과**

<p align="center">
  <a href="#">
    <img src="/images/SRCNN/figure7.jpg" height="200" />
  </a>
  <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  <b>[ Figure 4 : A Larger Filter Size Leads to Betters Results ]</b> 
</p>

필터 크기를 증가시킴에 따라 성능이 더 좋아지는 것을 확인할 수 있다. 그러나 9-5-5 의 복잡도는 9-3-3 의 약 2배 가량 크기때문에, 적당한 필터 크기를 설정하는 것이 더 좋은 것으로 보인다.

#### - Number of layers
**1. $n_{22} = 16, f_{22} = 1$**

크기가 $n_{22} = 16, f_{22} = 1$ 인 또다른 비선형 맵핑을 추가해 모델 구조를 더 깊게 구성하였다. 따라서 모델 구조가 각각 9-1-1-5, 9-3-1-5, 9-5-1-5 이고, 각각을 9-1-5, 9-3-5, 9-5-5 와 비교한다.

<p align="center">
  <a href="#">
    <img src="/images/SRCNN/figure8.jpg" height="500" />
  </a>
  <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  <b>[ Figure 5 : Comparison between Three-Layer and Four-Layer Networks ]</b> 
</p>


**2. $n_{22} = 32, f_{22} = 3$**

크기가 $$n_{22} = 32, f_{22} = 3$$ 이외에도 더 깊은 비선형 맵핑을 추가해 비교를 진행하였다.

<p align="center">
  <a href="#">
    <img src="/images/SRCNN/figure9.jpg" height="350" />
  </a>
  <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  <b>[ Figure 6 : Comparison between Three-Layer and Deeper Four-Layer Networks ]</b> 
</p>

충분한 시간동안 훈련했음에도 불구하고 세 실험에서 모두 3층으로 구성된 신경망이 대체로 수렴속도가 빠른 것을 확인할 수 있다. 즉, 신경망의 깊이가 깊은 것과 수렴속도, 성능 등은 항상 비례관계는 아니라는 것을 알 수 있다.


## 3.3. Color Channles 
컬러 이미지가 아닌 YCbCr 공간으로 변환해 Y (Luminance, 밝기(휘도)) 채널에만 초해상화 알고리즘을 적용한다. 이 때 Cb (Chrominance-Blue, 파란색 성분을 나타내는 색차 채널)와 Cr (Chrominance-Red, 빨간색 성분을 나타내는 색차 채널) 은 bicubic 보간법으로 업스캐일링을 진행한다.

#### - Details
학습 데이터 셋 : 91-image dataset
평가 데이터 셋 : $Set5$
신경망 구성 : $c=3, f_1 = 9, f_2 = 1, f_3 = 5, n_1 = 64, n_2 = 32$
upscaling factor = 3

#### - Results

<p align="center">
  <a href="#">
    <img src="/images/SRCNN/table5.jpg" height="200" />
  </a>
  <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  <b>[ Table 2 : Average PSNR of different Channels & Training Strategies on the Set5 ]</b> 
</p>

$$\mathbf{Y \; pre-train}$$ : Y 의 변화에 따른 성능 차이를 확인하기 위해 신경망을 사전학습할 때 Y 채널의 MSE 만을 손실함수로 사용한다.

위 결과를 통해 YCrCb 색상 공간을 사용함으로써 필요한 연산량이 줄어들고, 결과 이미지의 품질이 정량적 지표에서도 높은 성능을 보이는 것을 알 수 있다. 따라서 위 실험들에서 SRCNN 은 컬러 이미지에서도 효율적이고 우수한 초해상화 성능을 보임을 알 수 있다.