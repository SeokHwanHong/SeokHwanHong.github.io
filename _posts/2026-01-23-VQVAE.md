---
layout: single        # 문서 형식
title: Neural Discrete Representation Learning(2018)        # 제목
categories: Generative Model   # 카테고리
tag: [DL, Image, AE, Quantization]
sidebar_main : true # 좌측 글 목록

author_profile: true  # 사이드바 visible 여부
sidebar:              # 페이지 왼쪽에 카테고리 지정
    nav: "counts"       # sidebar의 주소 지정
#search: false # 블로그 내 검색 비활성화
use_math: true
---
# Keywords
Image Generation, AutoEncoder, Variational AutoEncoder, Vector Quantization, Discrete


# 1. Introduction
기존의 VAE 는 잠재공간(latent space)을 연속적인 확률 분포(가우시안 확률 분포)로 가정한다. 하지만 우리가 다루는 데이터(이미지, 음성, 텍스트)는 이산적인 속성을 갖고 있다. 기존의 모델들은 데이터의 본질적 특징들을 이해하지 못하며 사후 확률 붕괴 현상이 존재한다. 본 논문에서는 벡터 양자화 (vector quatization, VQ)를 도입해 이와 같은 문제들을 해결하고자 하며 더 효율적이고 뛰어난 성능을 실험적으로 증명한다. 


# 2. VQ-VAE
## 2.1. VAE
#### - Notation
$$ \mathcal{E} $$ : encoder

$$ \mathcal{D} $$ : decoder

$$ x $$ : input data

$$ z $$ : discrete latent random variable

$$ p(z) $$ : a prior distribution

$$ q(z \vert x) $$ : posterior distribution

$$ p(x \vert z) $$ : a distribution for input $$x$$ given $$z$$


#### - Architecture

<p align="center">
  <a href="#">
    <img src="/images/VQVAE/vqvae1.jpg" height="225" />
  </a>
  <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  <b>[ Figure 1 : The type of directed graphical model of VAE under consideration ]</b> 
</p>

**1. 인코더**

입력 데이터 $$x$$ 를 잠재 공간의 평균($$\mu$$) 와 표준편차 ($$\sigma$$) 값으로 변환한다.


**2. 잠재 공간**
데이터의 핵심 특징이 압축된 공간이다. VAE 내 사전 확률 분포와 사후 확률 분포는 모두 가우시안 분포를 가정한다 ($$\sum \mathcal{N}(0, \Sigma) \text{ where } \Sigma \; : \; diagonal matrix $$). 이를 적용함으로서 재모수화를 사용해 샘플링을 진행하는데, 이는 모델이 미분 가능하여 학습될 수 있도록 돕는다.

**3. 디코더**
잠재 공간에서 샘플링된 벡터를 다시 원래 데이터 형태로 복원한다.


#### - Variational
VAE의 목표는 단순히 똑같은 이미지를 만드는 것이 아니라, 그럴듯한 새로운 데이터를 생성하는 것이다. 

**1.연속적인 잠재 공간**

데이터를 분포로 학습하기 때문에, 잠재 공간의 특정 지점들을 이동하며 데이터의 특징이 부드럽게 변하는 결과를 얻을 수 있다.


**2. 생성 능력**
학습이 끝난 후 디코더에 임의의 잠재 벡터를 넣어주면, 새로운 이미지를 생성한다. 

#### - 손실 함수
$$Loss = \mathcal{L}_{Recon} + \text{KL Divergence}$$

$$\mathcal_{L}_{Recon}$$ : 복원 손실. 출력값이 입력값과 얼마나 비슷한지를 측정

$$\text{KL Divergence}$$ : 학습된 잠재 공간의 분포가 사전에 가정한 가우시안 분포와 너무 멀어지지 않도록 규제.


## 2.2. Discrete Latent Variables
#### - Notation

$$K$$ : 이산 잠재 공간의 크기

$$D$$ : 각 임베딩 벡터 $$e_i$$ 의 차원(특징)

$$e_i$$ : 사전에 정의된 임베딩 벡터

$$e \in \mathbb{R}^{K \times D}$$ : 잠재 임베딩 공간



#### - 인코딩
입력값 $$x$$ 가 인코더 $$\mathcal{E}$$ 를 통과해 결과물 $$z_e(x)$$ 를 생성한다. 즉, 잠재 공간으로의 임베딩 벡터로 변환한다. 그리고 이산 잠재 변수인 $$z$$ 는 다음과 같은 식을 통해 사전에 정의된 임베딩 벡터 $$e$$ 로 근사된다.

$$
\begin{split}
  q(z=k \vert x) = 
  \begin{cases} 
    &1 \text{ for } k = argmin_j \Vert z_e(x) - e_i \Vert_{2} \\
    &0 \text{ otherwise }
  \end{cases}
\end{split}
$$

여기서 $$z_e(x)$$ 는 인코더를 통과한 후의 벡터이다. 이는 원-핫 인코딩을 이용한 사후 범주 확률 분포이다. 이후 디코더의 입력값은 다음과 같다.

$$
\begin{split}
  z_q(x) = e_k, \quad \text{where} \quad k=argmin_j \Vert z_e(x) - e_j \Vert_{2}
\end{split}
$$

모수가 존재하는 부분은 인코더, 디코더, 임베딩 공간까지 총 3개이다. 위와 같은 식들을 이용해 임베딩 벡터로 만드는 이유는 우리가 음성이나 이미지, 비디오와 같은 데이터에서 각각 1, 2, 3차원 데이터를 뽑고 이를 이산적으로 표현할 수 있기 때문이다. 필자들은 VAE를 ELBO로 $$\log p(x)$$ 의 경계를 설정할 수 있다는 부분에 초점을 맞춘다. 제안한 사후 범주 확률 분포는 결정적(deterministic)이고 $$z$$ 에 대한 간단한 균등 사전 분포를 정의했기 때문에, KL 발산 상수를 $$\log K$$ 로 이용할 수 있다.



## 2.3. Learning
<p align="center">
  <a href="#">
    <img src="/images/VQVAE/figure.jpg" height="225" />
  </a>
  <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  <b>[ Figure 2 : A Figure Describing the VQ-VQE ]</b> 
</p>

$$z_q(x)$$ 의 경우 실제 기울기(gradient) 가 없기 때문에, Straight-Through Estimator (STE) 를 이용한다. 즉, 디코더 입력값인 $$z_q(x)$$ 부터 인코더의 결과값인 $$z_e(x)$$ 의 값을 복사해 사용한다. 이 기법을 이용해 인코더는 특징 추출 능력을, 디코더는 생성 능력을 동시에 학습할 수 있게 된다. 학습 중에는 인코더와 디코더가 동일한 크기의 차원을 공유하기 때문에 디코더가 가리키는 방향을 인코더가 그대로 따라가기만 해도 학습이 성공적으로 이루어진다. 

#### - Loss Function
전체 손실함수는 다음과 같이 세 가지 항으로 구성된다.

$$
\begin{split}
  L = \log p(x \vert z_q(x)) + \Vert sg[z_e(x)] - e \Vert_{2}^{2} + \beta \cdot \Vert z_e(x) - sg[e] \Vert_{2}^{2}
\end{split}
$$

첫 번째 항은 STE를 이용해 디코더와 인코더를 최적화하는 복원 손실이다. $$z_e(x)$$ 부터 $$z_q(x)$$ 로 매핑된 STE 로 인해 임베딩 $$e_i$$ 는 복원 손실 $$\log p(z \vert z_q(x))$$ 로부터 어떠한 기울기를 받지 않는다. 두 번째 항은 코드북 벡터 $$e$$ 가 인코더 출력값 $$z_e(x)$$ 과 가까워지도록 업데이트함으로써 코드북 학습을 유도한다. 마지막 항은 commitment 손실로 인코더 출력값이 코드북 벡터에서 너무 멀어지지 않도록 강제한다. 잠재 공간의 부피는 제한이 없기 때문에 출력값의 변동을 방지해 인코더가 특정 코드북 벡터 범위 내에 존재하도록 유도한다. VAE와 달리 사전 분포를 균등 분포로 가정했기에 앞서 말한데로 인코더 파라미터에 대해 KL 발산항이 상수로 되어 최적화 과정에서 무시할 수 있다. 전체 모델 $$\log p(x)$$ 의 로그 가능도는 다음과 같이 표현할 수 있다.

$$
\begin{split}
  \log p(x) = \log \sum_k p(x \vert z_k) \; p(z_k),
\end{split}
$$

MAP 추론 방식으로부터 $$z=z_q(x)$$ 라는 사실을 이용해 디코더 $$p(x \vert z)$$ 는 학습되었기 때문에, 모델이 수렴하면 디코더는 선택되지 않은 다른 벡터 $$(z \neq z_q(x))$$ 에 대한 확률은 배제한다. 따라서 모델을 다음과 같이 근사할 수 있다.

$$
\begin{split}
  \log p(x) \approx \log p(x \vert z_q(x)) \cdot p(z_q(x))
\end{split}
$$

따라서 Jensen 부등식을 이용하면, 다음과 같이 표현할 수 있다.

$$
\begin{split}
  \log p(x) \le \log p(x \vert z_q(x)) \cdot p(z_q(x))
\end{split}
$$


## 2.4. Prior
모델을 학습할 때는 사전 분포 $$p(z)$$ 를 균등 분포로 고정한다. 왜냐하면 인코더와 디코더가 먼저 데이터의 핵심 특징을 뽑아내고 코드북을 구성하는 데에만 집중하도록 유도하기 위함이다. 이후 학습이 끝나면 이미지는 코드북 인덱스의 나열로 치환할 수 있다. 저자들은 PixelCNN을 이용해 이미지 데이터를 처리하고 음성 데이터에 대해서는 WaveNet을 이용했다. 




# 3. Experiments
## 3.1. Comparison with continuous variables







# 참고
https://lcyking.tistory.com/entry/%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0-Swin-Transformer-Hierarchical-Vision-Transformer-using-Shifted-Windows