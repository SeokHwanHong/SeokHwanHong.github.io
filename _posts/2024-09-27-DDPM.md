---
layout: single        # 문서 형식
title: Denosing Diffusion Probabilisticc Models (2020) # 제목
categories: Generative Model    # 카테고리
tag: [DL, Image, Generative, Diffusion]
author_profile: false # 홈페이지 프로필이 다른 페이지에도 뜨는지 여부
sidebar:              # 페이지 왼쪽에 카테고리 지정
    nav: "counts"       # sidebar의 주소 지정
#search: false # 블로그 내 검색 비활성화
use_math: true
---
# Keywords
Diffusion, Markov Process, generative model, Gaussian Noise


# 1. Introduction
## 1.1. Deffusion Models
#### - Revese Process

$\mathbf{x_1}, \dots \mathbf{x_T}$ : 데이터 $\mathbf{x}_0 \sim q(\mathbf{x}_0)$ 와 동일한 차원의 잠재 변수

$$p_{\theta}(\mathbf{x}_{0:T}) := \int p_{\theta}(\mathbf{x}_{0:T}) d\mathbf{x}_{0:T}$$ : 잠재변수모형, 후진과정

$$
\begin{split}
    p_{\theta}(\mathbf{x}_{0:T}) := p(\mathbf{x}_T) \prod_{t=1}^T p_{\theta}(\mathbf{x}_{t-1} \vert \mathbf{x}_{t}), \quad p_{\theta}(\mathbf{x}_{t-1} \vert \mathbf{x}_{t}) := \mathcal{N}(\mathbf{x}_{t-1} ; \mathbf{\mu}_{\theta}(\mathbf{x}_t, t), \mathbf{\Sigma}_{\theta}(\mathbf{x}_t, t))
\end{split}
$$

이는 학습된 Gaussian Noise이 $p(\mathbf{x}_t) = \mathcal{N}(\mathbf{x}_T; \mathbf{0}, \mathbf{I})$ 에서 시작하는 Markov Chain으로 정의된다. 


#### - Forward Process
디퓨전 모형이 다른 모형들과 구분되는 특징은 근사 사후 분포인 $q(\mathbf{x}_{1:T} \vert \mathbf{x}_0)$ 가 varaince schedule $\beta_t$ 에 따라 데이터에 점진적으로 Gaussian noise를 추가하는 Markov Chain 로 고정된다는 것이다. 

$$
\begin{split}
    q_{\theta}(\mathbf{x}_{1:T} \vert \mathbf{x}_0) := \prod_{t=1}^T q_{\theta}(\mathbf{x}_{t} \vert \mathbf{x}_{t-1}), \quad q_{\theta}(\mathbf{x}_{t} \vert \mathbf{x}_{t-1}) := \mathcal{N}(\mathbf{x}_{t} ; \sqrt{1-\beta_t}\mathbf{x}_{t-1}, \beta_t \mathbf{I})
\end{split}
$$

여기서 $\sqrt{1-\beta_t}$ 는 원본 데이터가 유지되는 정도를 의미한다.

#### - Training
학습은 negative log 가능도에 대한 일반적인 변분 경계를 최적화 하는 방식으로 진행되고, 이는 다음과 같이 표현된다.

$$
\begin{split}
    \mathbb{E}[-\log p_{\theta}(\mathbf{x}_0)] \le 
    \mathbb{E}_q \left[ -\log \frac{p_{\theta}(\mathbf{x}_{0:T})}{q(\mathbf{x}_{1:T} \vert \mathbf{x}_0)} \right] = 
    \mathbb{E}_q \left[ -\log p(\mathbf{x}_T) -\sum _{t \ge 1} \log \frac{p_{\theta}(\mathbf{x}_{t-1} \vert \mathbf{x}_t)}{q(\mathbf{x}_{t} \vert \mathbf{x}_{t-1})} \right] 
    =: L
\end{split}
$$

전진과정의 분산 $$\beta_t$$ 는 reparameterization 에 의해 학습되거나, hyperparameter로 고정된다. 그리고 전진과정과 후진과정이 동일한 함수 형태를 가정하기 때문에 전진과정에서의 Gaussian 조건부를 선택함으로써 부분적으로 모형이 복잡한 데이터 분포를 잘 근사하고 생성할 수 있는 능력을 보장한다. 즉, 시간에 따라 데이터에 추가할 노이즈의 양을 결정한다. 따라서 SGD 를 이용해 무작위 상태의 $L$ 을 최적화해 충분히 학습이 가능하다. 여기서 새로운 파라미터인 $$\alpha_t = 1 - \beta_t$$ 를 추가하는데, 이는 원본 데이터가 시간 단계 $t$ 에서 얼마나 남아있는 지를 결정한다. 또한 $$\bar{\alpha}_t = \prod_{s=1}^t \alpha_s$$ 는 전체시간 단계까지의 누적된 값을 고려한다. 그리고 이를 이용해 다음과 같이 표현하면 분산을 감소시켜 더 좋은 성능을 낼 수 있다.

$$
\begin{split}
    q(\mathbf{x}_t \vert \mathbf{x}_0) = \mathcal{L}(\mathbf{x}_t ; \sqrt{\bar{\alpha}_t} \mathbf{x}_0, (1-\bar{\alpha}) \mathbf{I})
\end{split} 
$$

$$
\begin{split}
    L = \mathbb{E}_q [\underbrace {D_{KL} (q(\mathbf{x}_T \vert \mathbf{x}_0)  \Vert p(\mathbf{x}_T))}_{L_T} + \sum_{t>1} \underbrace {D_{KL} (q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0) \Vert p_{\theta}(\mathbf{x}_{t-1} \vert \mathbf{x}_t))}_{L_{t-1}} - \underbrace{\log p_{\theta}(\mathbf{x}_0 \vert \mathbf{x}_1)}_{L_0}]
\end{split}
$$

이는 정규분포들 간의 비교이므로 분산이 높은 Monte Carlo 추정치보다 닫힌 형태의 Rao-Blackwellized 식으로 계산할 수 있다.




# 2. Diffusion Models & Denosing Autoencdoers
## 2.1. Forward process & $L_T$
$\beta_t$ 가 재매개변수화로 학습이 가능하고 사후분포 $q$ 에는 학습가능한 파라미터가 없어서 $L_T$ 를 상수로 설정한다.


## 2.2. Reverse process & $L_{T-1}$
$$p_{\theta} (\mathbf{x}_{t-1} \vert \mathbf{x}_{t}) = \mathcal{N}(\mathbf{x}_{t-1} ; \mathbf{\mu}_{\theta} , \Sigma_{\theta} (\mathbf{x}_t, t))$$ 에 대한 설정은 다음과 같다.


#### - Variance $\Sigma_{\theta}$
실험적으로 $$\sigma_t^2 = \beta_t$$ (데이터가 정규분포를 따르는 경우) 와 $$\sigma_t^2 = \tilde{\beta}_t = \frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t} \beta_t$$ (데이터가 고정된 한 점에 수렴하는 경우) 는 같은 결과를 갖기 때문에 $$\Sigma_{\theta}(\mathbf{x}_t, t) = \sigma_t^2 \mathbf{I}$$ 로 설정한다.


#### - Mean $\mu_{\theta}$
$\mathbf{x}_0$ 가 주어졌을 때, 전진과정은 다음과 같이 표현할 수 있다.

$$
\begin{split}
    q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0) = \mathcal{N}(\mathbf{x}_{t-1} ; \tilde{\mathbf{\mu}}_t (\mathbf{x}_t, \mathbf{x}_0) , \tilde{\beta}_t\mathbf{I}),
\end{split}
$$

$$
\begin{split}
    \text{where} \quad \tilde{\mathbf{\mu}}_t (\mathbf{x}_t, \mathbf{x}_0) := \frac{\sqrt{\bar{\alpha}_{t-1}} \beta_t}{1-\bar{\alpha}_t} \mathbf{x}_0 + \frac{\sqrt{\bar{\alpha}}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t} \mathbf{x}_t \quad 
    \text{and} \quad \tilde{\beta}_t := \frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t} \beta_t
\end{split}
$$

이는 $$t$$ 번째 시간단계에서의 평균값을 표현한 것인데, 최초 상태인 $$\mathbf{x}_0$$ 와 $$t$$ 번째 시간단계 $$\mathbf{x}_t$$ 의 가중합이다. $$\mathbf{x}_0$$ 의 가중치는 원본 데이터에서 직접적으로 역추적 가능한 때를 반영한다. 시간의 흐름에 따라 원본 데이터가 회복되면서 비중이 증가한다. 그리고 $$\mathbf{x}_t$$ 의 가중치는 완전한 복원이 이루어지지 않은 시간 단계에서 복원에 필요한 정보를 제공한다. 시간이 흐를수록 비중은 감소한다. 또한, $$\Sigma_{\theta} (\mathbf{x}_t, t) = \sigma_t^2 \mathbf{I}$$ 로 설정했기 때문에 재매개변수화를 통해 평균을 다음과 같이 표현할 수 있다.

$$
\begin{split}
    L_{t-1} = \mathbb{E}_q \left[ \frac{1}{2 \sigma_t^2} \Vert \tilde{\mathbf{\mu}}_t(\mathbf{x}_t, \mathbf{x}_{0}) - \mathbf{\mu}_{\theta}(\mathbf{x}_t,t) \Vert^2 \right] + C
\end{split}
$$

여기서 $C$ 는 $$\theta$$ 와 무관한 상수이다. 위 식에서 $$\mathbf{x}_t(\mathbf{x}_0 , \mathbf{\epsilon}) = \sqrt{\bar{\alpha}_t} \mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t} \mathbf{\epsilon}, \; \epsilon \sim \ \mathcal{N}(\mathbf{0}, \mathbf{I})$$ 을 이용하면 다음과 같이 표현할 수 있다.

$$
\begin{split}
    L_{t-1} - C &= \mathbb{E}_{\mathbf{x}_0, \mathbf{\epsilon}} \left[\frac{1}{2 \sigma_t^2} \Vert \tilde{\mathbf{\mu}}_t (\mathbf{x}_t (\mathbf{x}_0, \mathbf{\epsilon}), \frac{1}{\sqrt{\bar{\alpha}_t}} (\mathbf{x}_t (\mathbf{x}_0, \epsilon) - \sqrt{1-\bar{\alpha}_t} \mathbf{\epsilon} ) ) - \mathbf{\mu}_{\theta} (\mathbf{x}_t (\mathbf{x}_0, \mathbf{\epsilon}), t ) \Vert^2 \right]  \\
    &= \mathbb{E}_{\mathbf{x}_0, \mathbf{\epsilon}} \left[ \frac{1}{2 \sigma_t^2} \Vert \frac{1}{\sqrt{\alpha_t}} (\mathbf{x}_t (\mathbf{x}_0, \mathbf{\epsilon}) - \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}} \mathbf{\epsilon}) - \mathbf{\mu}_{\theta} (\mathbf{x}_t (\mathbf{x}_0, \mathbf{\epsilon}), t) \Vert^2 \right]
\end{split}
$$

이를 통해 $$\mathbf{\mu}_{\theta}$$ 가 반드시 $$\mathbf{x}_t$$ 가 주어졌을 때, $$\frac{1}{\sqrt{\alpha}_t}(\mathbf{x}_t - \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\mathbf{\epsilon})$$ 를 예측한다는 것을 알 수 있다. $$\mathbf{\mu}_{\theta}$$ 로 다시 표현하면 다음과 같다.

$$
\begin{split}
    \mathbf{\mu}_{\theta} (\mathbf{x}_t, t) = \tilde{\mathbf{\mu}}_t \left( \mathbf{x}_t, \frac{1}{\sqrt{\bar{\alpha}_t}}(\mathbf{x}_t - \sqrt{1-\bar{\alpha}_t} \mathbf{\epsilon}_{\theta}(\mathbf{x}_t)) \right) = \frac{1}{\sqrt{\alpha_t}}(\mathbf{x}_t - \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}} \mathbf{\epsilon}_{\theta}(\mathbf{x}_t, t))
\end{split}
$$

여기서 $\mathbf{\epsilon}_{\theta}$ 는 $\mathbf{x}_t$ 로부터 $\epsilon$ 을 예측하기 위한 함수 근사기이다. 이를 이용해 후진과정에서 표본을 뽑는 알고리즘은 다음과 같다.

<p align="center">
  <a href="#">
    <img src="/images/DDPM/algorithm2.jpg" height="200" />
  </a>
  <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  <b>[ Algorithm2 : Sampling from Reverse process ]</b> 
</p>


또한 $\mathbf{\mu}_{\theta}(\mathbf{x}_t, t)$를 다시 $L_{t-1} - C$ 에 대입하면 다음과 같이 표현할 수 있다.

$$
\begin{split}
    L_{t-1} - C = \mathbb{E}_{\mathbf{x}_0, \epsilon} \left[ \frac{\beta_t^2}{2 \sigma_t^2 \alpha_t (1-\bar{\alpha}_t)} \Vert \mathbf{\epsilon} - \epsilon_{\theta}(\sqrt{\bar{\alpha}_t} \mathbf{x}_0 + \sqrt{1-\bar{\alpha}_t} \mathbf{\epsilon}, t) \Vert^2 \right]
\end{split}
$$

따라서 역방향 과정의 평균 함수 근사기 $$\mu_{\theta}$$ 로 $$\tilde{\mu}_t$$ 이나 매개변수를 조정해 $$\epsilon$$ 를 예측하도록 훈련할 수 있다.



## 3.3. Data scaling, Reverse process decoder, and $L_0$
역과정이 신경망 내에서 작동할 수 있도록 입력값들의 크기 {0, 1, ... , 255} 를 [-1,1] 로 변환한다. 그리고 역과정을 이산화된 로그 가능도로 표현하면 다음과 같다.

$$
\begin{split}
    p_{\theta}(\mathbf{x}_0 \vert \mathbf{x}_1) &= \prod_{i=1}^D \int_{\delta_{-} (x_0^i)}^{\delta_{+}(x_0^i)} \mathcal{N}(x ; \mu_{\theta}^i(\mathbf{x}_1,1), \sigma_1^2) \; dx \\
    \delta_{+}(x) &= \begin{cases} \inf & \text{if } x = 1 \\ x + \frac{1}{255} & \text{if } x < 1 \end{cases}, 
    \quad \delta_{-}(x) = \begin{cases} -\inf & \text{if } x = -1 \\ x - \frac{1}{255} & \text{if } x > -1 \end{cases}
\end{split}
$$

$D$ 는 데이터의 차원을, $i$ 는 특정 좌표를 의미한다. 이는 변분 경계가 이산 데이터의 정보 손실이 없도록 일정한 코드 길이를 유지하며 데이터에 노이즈를 추가하거나 스케일링 연산 시 Jacobian을 로그 가능도에 포함하지 않도록 구성해 연산량 역시 일정하게 유지한다.

## 3.4. Simplified training objective
훈련 과정에서 표본을 더 간단하고 좋게 추출하는 방법은 다음과 같다.

$$
\begin{split}
    L_{simple}(\theta) := \mathbb{E}_{(t, \mathbf{x}_0, \epsilon)} [\Vert \mathbf{\epsilon} - \mathbf{\epsilon}_{\theta} (\sqrt{\bar{\alpha}_t} \mathbf{x}_0 + \sqrt{1-\bar{\alpha}_t} \mathbf{\epsilon} , t) \Vert^2]
\end{split}
$$

즉, 손실함수에서 시간 단계 $t$ 에 따른 가중치를 통해, 모델이 노이즈 제거 작업에 집중할 수 있도록 설계했다. 특히 $t$ 가 작은 경우 가중치를 줄여 복잡한 노이즈 제거에 집중하는 것이 표본의 품질을 향상시키는데 도움이 된다.



# 참고
https://jang-inspiration.com/ddpm-2
