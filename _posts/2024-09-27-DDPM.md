---
layout: single        # 문서 형식
title: Denosing Diffusion Probabilisticc Models (2020) # 제목
categories: Generative Model    # 카테고리
tag: [DL, Image, Generative, Diffusion]
author_profile: false # 홈페이지 프로필이 다른 페이지에도 뜨는지 여부
sidebar:              # 페이지 왼쪽에 카테고리 지정
    nav: "docs"       # sidebar의 주소 지정
#search: false # 블로그 내 검색 비활성화
use_math: true
---
# Keywords
Diffusion, Markov Process, generative model, Gaussian Noise


# 1. Introduction
## 1.1. Deffusion Models
#### - Revese Process

$\mathbf{x_1}, \dots \mathbf{x_T}$ : 데이터 $\mathbf{x}_0 \sim q(\mathbf{x}_0)$ 와 동일한 차원의 잠재 변수
$p_{\theta}(\mathbf{x}_{0:T}) := \int p_{\theta}(\mathbf{x}_{0:T}) d\mathbf{x}_{0:T}$ : 잠재변수모형, 후진과정

$$
p_{\theta}(\mathbf{x}_{0:T}) := p(\mathbf{x}_T) \prod_{t=1}^T p_{\theta}(\mathbf{x}_{t-1} | \mathbf{x}_{t}), \quad p_{\theta}(\mathbf{x}_{t-1} | \mathbf{x}_{t}) := \mathcal{N}(\mathbf{x}_{t-1} ; \mathbf{\mu}_{\theta}(\mathbf{x}_t, t), \mathbf{\Sigma}_{\theta}(\mathbf{x}_t, t))
$$

이는 학습된 Gaussian Noise이 $p(\mathbf{x}_t) = \mathcal{N}(\mathbf{x}_T; \mathbf{0}, \mathbf{I})$ 에서 시작하는 Markov Chain으로 정의된다. 


#### - Forward Process
디퓨전 모형이 다른 모형들과 구분되는 특징은 근사 사후 분포인 $q(\mathbf{x}_{1:T} | \mathbf{x}_0)$ 가 varaince schedule $\beta_t$ 에 따라 데이터에 점진적으로 Gaussian noise를 추가하는 Markov Chain 로 고정된다는 것이다. 

$$
q_{\theta}(\mathbf{x}_{1:T} | \mathbf{x}_0) := \prod_{t=1}^T q_{\theta}(\mathbf{x}_{t} | \mathbf{x}_{t-1}), \quad q_{\theta}(\mathbf{x}_{t} | \mathbf{x}_{t-1}) := \mathcal{N}(\mathbf{x}_{t} ; \sqrt{1-\beta_t}\mathbf{x}_{t-1}, \beta_t \mathbf{I})
$$

여기서 $\sqrt{1-\beta_t}$ 는 원본 데이터가 유지되는 정도를 의미한다.

#### - Training
학습은 negative log 가능도에 대한 일반적인 변분 경계를 최적화 하는 방식으로 진행되고, 이는 다음과 같이 표현된다.

$$
\mathbb{E}[-\log p_{\theta}(\mathbf{x}_0)] \le \mathbb{E}_q [ -\log \frac{p_{\theta}(\mathbf{x}_{0:T})}{q(\mathbf{x}_{1:T} | \mathbf{x}_0)} ] = \mathbb{E}_q [ -\log p(\mathbf{x}_T) -\sum _{t \ge 1} \log \frac{p_{\theta}(\mathbf{x}_{t-1} | \mathbf{x}_t)}{q(\mathbf{x}_{t} | \mathbf{x}_{t-1})} ] =: L
$$

전진과정의 분산 $\beta_t$ 는 reparameterization 에 의해 학습되거나, hyperparameter로 고정된다. 그리고 전진과정과 후진과정이 동일한 함수 형태를 가정하기 때문에 전진과정에서의 Gaussian 조건부를 선택함으로써 부분적으로 모형이 복잡한 데이터 분포를 잘 근사하고 생성할 수 있는 능력을 보장한다. 즉, 시간에 따라 데이터에 추가할 노이즈의 양을 결정한다. 따라서 SGD 를 이용해 무작위 상태의 $L$ 을 최적화해 충분히 학습이 가능하다. 여기서 새로운 파라미터인 $\alpha_t = 1 - \beta_t$ 를 추가하는데, 이는 원본 데이터가 시간 단계 $t$ 에서 얼마나 남아있는 지를 결정한다. 또한 $\bar{\alpha}_t = \prod_{s=1}^t \alpha_s$ 는 전체시간 단계까지의 누적된 값을 고려한다. 그리고 이를 이용해 다음과 같이 표현하면 분산을 감소시켜 더 좋은 성능을 낼 수 있다.

$$
q(\mathbf{x}_t | \mathbf{x}_0) = \mathcal{L}(\mathbf{x}_t ; \sqrt{\bar{\alpha}_t} \mathbf{x}_0, (1-\bar{\alpha}) \mathbf{I}) 
$$

$$
L = \mathbb{E}_q [\underbrace {D_{KL} (q(\mathbf{x}_T | \mathbf{x}_0)  || p(\mathbf{x}_T))}_{L_T} + \sum_{t>1} \underbrace {D_{KL} (q(\mathbf{x}_{t-1} |\mathbf{x}_t, \mathbf{x}_0) || p_{\theta}(\mathbf{x}_{t-1} | \mathbf{x}_t))}_{L_{t-1}} - \underbrace{\log p_{\theta}(\mathbf{x}_0 | \mathbf{x}_1)}_{L_0}]
$$

이는 정규분포들 간의 비교이므로 분산이 높은 Monte Carlo 추정치보다 닫힌 형태의 Rao-Blackwellized 식으로 계산할 수 있다.




# 2. Diffusion Models & Denosing Autoencdoers
## 2.1. Forward process & $L_T$
$\beta_t$ 가 재매개변수화로 학습이 가능하고 사후분포 $q$ 에는 학습가능한 파라미터가 없어서 $L_T$ 를 상수로 설정한다.

## 2.2. Reverse process & $L_{T-1}$
$p_{\theta} (\mathbf{x}_{t-1} | \mathbf{x}_{t}) = \mathcal{N}(\mathbf{x}_{t-1} ; \mathbf{\mu}_{\theta} , \Sigma_{\theta} (\mathbf{x}_t, t))$ 에 대한 설정은 다음과 같다.

#### - Variance $\Sigma_{\theta}$
실험적으로 $\sigma_t^2 = \beta_t$ (데이터가 정규분포를 따르는 경우) 와 $\sigma_t^2 = \tilde{\beta}_t = \frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t} \beta_t$ (데이터가 고정된 한 점에 수렴하는 경우) 는 같은 결과를 갖기 때문에 $\Sigma_{\theta}(\mathbf{x}_t, t) = \sigma_t^2 \mathbf{I}$ 로 설정한다.

#### - Mean $\mu_{\theta}$
$\mathbf{x}_0$ 가 주어졌을 때, 전진과정은 다음과 같이 표현할 수 있다.

$$
q(\mathbf{x}_{t-1} | \mathbf{x}_t, \mathbf{x}_0) = \mathcal{N}(\mathbf{x}_{t-1} ; \tilde{\mathbf{\mu}}_t (\mathbf{x}_t, \mathbf{x}_0) , \tilde{\beta}_t\mathbf{I}),
$$

$$
where \quad \tilde{\mathbf{\mu}}_t (\mathbf{x}_t, \mathbf{x}_0) := \frac{\sqrt{\bar{\alpha}_{t-1}} \beta_t}{1-\bar{\alpha}_t} \mathbf{x}_0 + \frac{\sqrt{\bar{\alpha}}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t} \mathbf{x}_t \quad and \quad \tilde{\beta}_t := \frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t} \beta_t
$$

이는 t번째 시간단계에서의 평균값을 표현한 것인데, 최초 상태인 $\mathbf{x}_0$ 와 t번째 시간단계 $\mathbf{x}_t$ 의 가중합이다. $\mathbf{x}_0$ 의 가중치는 원본 데이터에서 직접적으로 역추적 가능한 때를 반영한다. 시간의 흐름에 따라 원본 데이터가 회복되면서 비중이 증가한다. 그리고 $\mathbf{x}_t$ 의 가중치는 완전한 복원이 이루어지지 않은 시간 단계에서 복원에 필요한 정보를 제공한다. 시간이 흐를수록 비중은 감소한다. 그리고 $\Sigma_{\theta} (\mathbf{x}_t, t) = \sigma_t^2 \mathbf{I}$ 로 설정했기 때문에 재매개변수화를 통해 평균을 다음과 같이 표현할 수 있다.

$$
L_{t-1} = \mathbb{E}_q [ \frac{1}{2 \sigma_t^2} || \tilde{\mathbf{\mu}}_t(\mathbf{x}_t, \mathbf{x}_{0}) - \mathbf{\mu}_{\theta}(\mathbf{x}_t,t) ||^2] + C
$$

여기서 $C$ 는 $\theta$ 와 무관한 상수이다. 위 식에서 $\mathbf{x}_t(\mathbf{x}_0 , \mathbf{\epsilon}) = \sqrt{\bar{\alpha}_t} \mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t} \mathbf{\epsilon}, \: \epsilon \sim \ \mathcal{N}(\mathbf{0}, \mathbf{I})$ 을 이용하면 다음과 같이 표현할 수 있다.

$$
\begin{split}
L_{t-1} - C &= \mathbb{E}_{\mathbf{x}_0, \mathbf{\epsilon}} [\frac{1}{2 \sigma_t^2} || \tilde{\mathbf{\mu}}_t (\mathbf{x}_t (\mathbf{x}_0, \mathbf{\epsilon}), \frac{1}{\sqrt{\bar{\alpha}_t}} (\mathbf{x}_t (\mathbf{x}_0, \epsilon) - \sqrt{1-\bar{\alpha}_t} \mathbf{\epsilon} ) ) - \mathbf{\mu}_{\theta} (\mathbf{x}_t (\mathbf{x}_0, \mathbf{\epsilon}), t ) ||^2 ]  \\
&= \mathbb{E}_{\mathbf{x}_0, \mathbf{\epsilon}} [ \frac{1}{2 \sigma_t^2} || \frac{1}{\sqrt{\alpha_t}} (\mathbf{x}_t (\mathbf{x}_0, \mathbf{\epsilon}) - \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}} \mathbf{\epsilon}) - \mathbf{\mu}_{\theta} (\mathbf{x}_t (\mathbf{x}_0, \mathbf{\epsilon}), t) ||^2 ]
\end{split}
$$

이를 통해 $\mathbf{\mu}_{\theta}$ 가 반드시 $\mathbf{x}_t$ 가 주어졌을 때, $\frac{1}{\sqrt{\alpha}_t}(\mathbf{x}_t - \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\mathbf{\epsilon}) $ 를 예측한다는 것을 알 수 있다. $\mathbf{\mu}_{\theta}$ 로 다시 표현하면 다음과 같다.

$$
\mathbf{\mu}_{\theta}(\mathbf{x}_t, t) = \tilde{\mathbf{\mu}}_t (\mathbf{x}_t, \frac{1}{\sqrt{\bar{\alpha}_t}}(\mathbf{x}_t - \sqrt{1-\bar{\alpha}_t} \mathbf{\epsilon}_{\theta}(\mathbf{x}_t))) = \frac{1}{\sqrt{\alpha_t}}(\mathbf{x}_t - \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}} \mathbf{\epsilon}_{\theta}(\mathbf{x}_t, t))
$$

여기서 $\mathbf{\epsilon}_{\theta}$ 는 $\mathbf{x}_t$ 로부터 $\epsilon$ 을 예측하기 위한 함수 근사기이다. 이를 이용해 후진과정에서 표본을 뽑는 알고리즘은 다음과 같다.

<figure style="text-align: center; display: inline-block; width: 100%;">
    <img src = "/images/DDPM/algorithm2.jpg" height = 200>    
    <figcaption style="display: block; width: 100%; text-align: center;">[ Algorithm2 : Sampling from Reverse process ]</figcaption>
</figure>

또한 $\mathbf{\mu}_{\theta}(\mathbf{x}_t, t)$를 다시 $L_{t-1} - C$ 에 대입하면 다음과 같이 표현할 수 있다.

$$
L_{t-1} - C = \mathbb{E}_{\mathbf{x}_0, \epsilon} [\frac{\beta_t^2}{2 \sigma_t^2 \alpha_t (1-\bar{\alpha}_t)} || \mathbf{\epsilon} - \epsilon_{\theta}(\sqrt{\bar{\alpha}_t} \mathbf{x}_0 + \sqrt{1-\bar{\alpha}_t} \mathbf{\epsilon}, t) ||^2 ]
$$

따라서 역방향 과정의 평균 함수 근사기 $\mu_{\theta}$ 로 $\tilde{\mu}_t$ 이나 매개변수를 조정해 $\epsilon$ 를 예측하도록 훈련할 수 있다.

## 3.3. Data scaling, Reverse process decoder, and $L_0$
역과정이 신경망 내에서 작동할 수 있도록 입력값들의 크기 {0, 1, ... , 255} 를 [-1,1] 로 변환한다. 그리고 역과정을 이산화된 로그 가능도로 표현하면 다음과 같다.

$$
\begin{split}
p_{\theta}(\mathbf{x}_0 | \mathbf{x}_1) &= \prod_{i=1}^D \int_{\delta_{-} (x_0^i)}^{\delta_{+}(x_0^i)} \mathcal{N}(x ; \mu_{\theta}^i(\mathbf{x}_1,1), \sigma_1^2) \: dx \\
\delta_{+}(x) &= \begin{cases} \inf & \text{if } x = 1 \\ x + \frac{1}{255} & \text{if } x < 1 \end{cases}, 
\quad \delta_{-}(x) = \begin{cases} -\inf & \text{if } x = -1 \\ x - \frac{1}{255} & \text{if } x > -1 \end{cases}
\end{split}
$$

$D$ 는 데이터의 차원을, $i$ 는 특정 좌표를 의미한다. 이는 변분 경계가 이산 데이터의 정보 손실이 없도록 일정한 코드 길이를 유지하며 데이터에 노이즈를 추가하거나 스케일링 연산 시 Jacobian을 로그 가능도에 포함하지 않도록 구성해 연산량 역시 일정하게 유지한다.

## 3.4. Simplified training objective
훈련 과정에서 표본을 더 간단하고 좋게 추출하는 방법은 다음과 같다.

$$
L_{simple}(\theta) := \mathbb{E}_{(t, \mathbf{x}_0, \epsilon)} [|| \mathbf{\epsilon} - \mathbf{\epsilon}_{\theta} (\sqrt{\bar{\alpha}_t} \mathbf{x}_0 + \sqrt{1-\bar{\alpha}_t} \mathbf{\epsilon} , t)||^2]
$$

즉, 손실함수에서 시간 단계 $t$ 에 따른 가중치를 통해, 모델이 노이즈 제거 작업에 집중할 수 있도록 설계했다. 특히 $t$ 가 작은 경우 가중치를 줄여 복잡한 노이즈 제거에 집중하는 것이 표본의 품질을 향상시키는데 도움이 된다.



# 참고
https://jang-inspiration.com/ddpm-2
