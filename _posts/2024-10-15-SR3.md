---
layout: single        # 문서 형식
title: Imgae Super-Resolution via Iterative Refinement (2021) # 제목
categories: Super-Resolution    # 카테고리
tag: [DL, Image, Generative, Diffusion]
toc: true             # 글 목차
toc_sticky : true
toc_label: 목차
author_profile: false # 홈페이지 프로필이 다른 페이지에도 뜨는지 여부
sidebar:              # 페이지 왼쪽에 카테고리 지정
    nav: "docs"       # sidebar의 주소 지정
#search: false # 블로그 내 검색 비활성화
use_math: true
---
# Keywords
Diffusion, Refinement, Super-Resolution, Deep Generative Model



# 1. Conditional Denoising Diffusion Model
#### - Notation

$\mathbf{x}$ : source image
$\mathbf{y} \in \mathbb{R}^d$ : target image 
$\mathbf{y}_T \sim \mathcal{N}(\mathbf{0}, \mathbf{I}) $ : pure noise image
$\mathcal{D} = \{ \mathbf{x}_i, \mathbf{y}_i \}_{i=1}^N \sim p(\mathbf{x}, \mathbf{y})$ : 미지의 분포에 대한 input-output 짝
$p(\mathbf{y}|\mathbf{x})$ : 1대다 mapping을 가지는 조건부 분포

#### - Conditional DDPM

<figure style="text-align: center; display: inline-block; width: 100%;">
    <img src = "/images/SR3/figure2.jpg" height = 150>    
    <figcaption style="display: block; width: 100%; text-align: center;">[ Figure 1 : Diffusion Process ]</figcaption>
</figure>

1. 정제 단계 $T$ 에 대해 목표 이미지 $\mathbf{y}_0$ 를 생성 

2. pure noise image $\mathbf{y}_T \sim \mathcal{\mathbf{0}, \mathbf{I}}$ 를 생성  

3. 모델이 결과물을 반복적으로 정제해 $(\mathbf{y_{T-1}}, \mathbf{y_{T-2}}, ... , \mathbf{y_{0}})$ 를 획득

4. $\mathbf{y}_0 \sim p(\mathbf{y}|\mathbf{x})$ 를 얻기 위해 조건부 분포 $p_{\theta} (\mathbf{y}_{t-1} | \mathbf{y}_t, \mathbf{x})$ 를 학습

forward diffusion process $q(\mathbf{y}_t | \mathbf{y}_{t-1})$ : 고정된 Markov chain을 통해 결과물에 점진적으로 Gaussian noise를 추가하는 과정

#### - Goal
$\mathbf{x}$ 에서 $\mathbf{y}$ 로 이미지를 정제하는 stochastic 반복 과정을 통해 $p(\mathbf{y} | \mathbf{x})$ 로 근사되는 모수적인 근사분포를 학습하는 것이 목표다. 즉, $\mathbf{x}$ 가 조건부로 주어졌을 때 역 Markov chain 을 통해 이미지를 정제함으로써 Gaussian diffusion 과정을 역방향으로 진행하는 것이다.

#### - Langevin Dynamics
확률적 샘플링 기법 중 하나로, 모델이 데이터의 잠재적인 확률 밀도 함수를 알고 있거나 이를 추정하기 위해 사용한다. 이 과정에서 데이터를 더 잘 설명가능한 분포를 탐색하는 방식이다. 기본 수식은 다음과 같다.

$$
x_{t+1} = x_t + \epsilon \nabla_x \log p(x_t) + \sqrt{2 \epsilon} z_t
$$

$\epsilon$ : step size
$\nabla_x \log p(x_t)$ : 로그 밀도함수의 기울기
$z_t$ : Gaussian Noise

이는 주로 확률적 최적화(local optima 에서 탈출), 복잡한 고차원 분포에서의 샘플링, 확률적 추론 등에 응용이 가능하다. 

## 1.1. Gaussian Diffusion Process
#### - Forward Process

$$
\begin{split}
q(\mathbf{y}_{1:T} | \mathbf{y}_0) &= \prod_{t=1}^T q(\mathbf{y}_t | \mathbf{y}_{t-1}), \\
q(\mathbf{y}_t | \mathbf{y}_{t-1}) &= \mathcal{N}(\mathbf{y}_t | \sqrt{\alpha_t} \mathbf{y}_{t-1}, (1-\alpha_t) \mathbf{I}), 
\end{split}
$$

$\alpha_{1:T} \in (0,1)$ : scalere parameter, 각 반복에서 노이즈의 분산을 결정, $t$ 가 무한대로 갈 때 분산을 제한

#### - Characterization
1. $\mathbf{y}_t$ 와 $\mathbf{y}_0$ 사이에 존재하는 모든 중간 과정을 고려하지않고, 중간 단계에서 적분

$$
q(\mathbf{y}_t | \mathbf{y}_0) = \mathcal{N}(\mathbf{y}_t | \sqrt{\gamma_t} \mathbf{y}_0, (1-\gamma_t) \mathbf{I})
$$

여기서 $\gamma_t = \prod_{i=1}^t \alpha_i$

2. 사후분포 유도

$$
\begin{split}
q(\mathbf{y}_{t-1} | \mathbf{y}_0, \mathbf{y}_t) &= \mathcal{N}(\mathbf{y}_{t-1} | \mathbf{\mu}, \sigma^2 \mathbf{I}) \\
\mathbf{\mu} &= \frac{\sqrt{\gamma_{t-1}}(1-\alpha_t)}{1-\gamma_t} \mathbf{y}_0 + \frac{\sqrt{\alpha_t}(1-\gamma_{t-1})}{1-\gamma_t} \mathbf{y}_t \\
\sigma^2 &= \frac{(1-\gamma_{t-1})(1-\alpha_t)}{1-\gamma_t}
\end{split}
$$

사후분포는 역과정을 parameterizing 할 때와 역과정에서 데이터의 로그 가능도에 대한 변분 하한을 계산할 때 도움이 된다.

## 1.2. Optimizing the Denosing Model
입력값으로 source image $\mathbf{x}$ 와 nosiy target image $\tilde{\mathbf{y}}$ 를 받는 denosing 신경망 모형 $f_{\theta}$ 를 최적화하는 것과 노이즈가 없는 깔끔한 이미지 $\mathbf{y_0}$ 를 복원하는 것이 목표다.
여기서 nosiy target image $\tilde{\mathbf{y}}$ 는 다음과 같다.

$$
\tilde{\mathbf{y}} = \sqrt{\gamma} \mathbf{y}_0 + \sqrt{1-\gamma} \mathbf{\epsilon}, \qquad \mathbf{\epsilon} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})
$$

그리고 각각의 목표에 대한 알고리즘은 다음과 같다.

<figure style="text-align: center; display: inline-block; width: 100%;">
    <img src = "/images/SR3/algorithm1.jpg" height = 150>    
    <figcaption style="display: block; width: 100%; text-align: center;">[ Algorithm 1 : Training a Denoising Model ]</figcaption>
</figure>

<figure style="text-align: center; display: inline-block; width: 100%;">
    <img src = "/images/SR3/algorithm2.jpg" height = 150>    
    <figcaption style="display: block; width: 100%; text-align: center;">[ Algorithm 2 : Inference in T Iterative Refinement Steps ]</figcaption>
</figure>

위 알고리즘에서 denoising model $f_{theta}$ 는 $\mathbf{x}, \mathbf{y}, \gamma$ 를 받는데, 입력값을 노이즈 $\gamma$ 의 분산에 대한 충분통계량으로 받고 nosie vector $\mathbf{\epsilon}$ 으로 예측하도록 훈련된다. 

#### - Objective Function

$$
\mathbb{E}_{(\mathbf{x}, \mathbf{y})}\mathbb{E}_{(\mathbf{\epsilon}, \gamma)} || f_{\theta}(\mathbf{x}, \underbrace{\sqrt{\gamma} \mathbf{y}_0 + \sqrt{1-\gamma} \mathbf{\epsilon}}_{\tilde{\mathbf{y}}}, \gamma) - \mathbf{\epsilon} ||_p^p
$$

where $ \mathbf{\epsilon} \sim \mathcal{N(\mathbf{0}, \mathbf{I})}, \: (\mathbf{x}, \mathbf{y}) \sim \mathcal{D}, \: p \in \{1,2\}, \: \gamma \sim p(\gamma) $
이 때 $p(\gamma)$ 는 모델과 생성되는 이미지의 품질에 많은 영향을 준다. 

## 1.3. Inference via Iterative Refinement
#### - Reverse Markovian Process

$$
\begin{split}
p_{\theta} (\mathbf{y}_{0:T} | \mathbf{x}) &= p(\mathbf{y}_T) \prod_{t=1}^T p_{\theta}(\mathbf{y}_{t-1} | \mathbf{y}_T, \mathbf{x}) \\
p(\mathbf{y}_T) &= \mathcal{N}(\mathbf{y}_T | \mathbf{0}, \mathbf{I}) \\
p_{\theta}(\mathbf{y}_{t-1} | \mathbf{y}_t, \mathbf{x}) &= \mathcal{N}(\mathbf{y}_{t-1} | \mu_{\theta} (\mathbf{x}, \mathbf{y}_t, \gamma_t), \sigma_t^2 \mathbf{I})
\end{split}
$$

동일한 Gaussian 조건부 분포인 $p_{\theta}(\mathbf{y}_{t-1} | \mathbf{y}_t, \mathbf{x})$ 의 관점에서 추론을 진행한다. 만약 $\alpha_{1:T} \approx 1$ 이면 $p_{\theta}(\mathbf{y}_{t-1} | \mathbf{y}_t, \mathbf{x})$ 은 정규분포로 근사한다. 반면에 $1-\gamma_t$ 가 충분히 커야 사전분포 $\mathbf{y}_{T}$ 가 사전분포 $p(\mathbf{y}_T) = \mathcal{N}(\mathbf{y}_{T} | \mathbf{0}, \mathbf{I})$ 로 근사할 수 있다.

#### - Rearrangement 
1. $\hat{\mathbf{y}}_0$
1.2 의 $\tilde{\mathbf{y}}$ 를 이용해 $\hat{\mathbf{y}}_0$ 를 정리하면 다음과 같다.

$$
\hat{\mathbf{y}}_0 = \frac{1}{\sqrt{\gamma_t}} (\mathbf{y}_t - \sqrt{1-\gamma_t} f_{\theta} (\mathbf{x}, \mathbf{y}_t, \gamma_t))
$$

2. mean of $p_{\theta}(\mathbf{y}_{t-1} | \mathbf{y}_t, \mathbf{x})$
Rearaangement 1의 식을 사후분포 $q(\mathbf{y}_{t-1} | \mathbf{y}_0, \mathbf{y}_t)$ 에 대입하면 다음과 같이 정리할 수 있다.

$$
\mu_{\theta} (\mathbf{x}, \mathbf{y}_t, \gamma_t) = \frac{1}{\sqrt{\alpha_t}} (\mathbf{y}_t - \frac{1-\alpha_t}{\sqrt{1- \gamma_t}} f_{\theta}(\mathbf{x}, \mathbf{y}_t, \gamma_t) )
$$

반면에 분산은 $1-\alpha_t$ 로 유도할 수 있다. 

3. $\mathbf{y}_{t-1}$
Rearrangment 1번과 2번을 이용해 각 반복에서 $\mathbf{y}_{t-1}$ 을 다음과 같은 형태로 사용할 수 있다.

$$
\mathbf{y}_{t-1} \leftarrow \frac{1}{\sqrt{\alpha_t}} (\mathbf{y}_t - \frac{1-\alpha_t}{\sqrt{1-\gamma_t}} f_{\theta}(\mathbf{x}, \mathbf{y}_t, \gamma_t)) + \sqrt{1-\alpha_t}\epsilon_t
$$

여기서 $f_{\theta}$ 가 주어진 데이터에 대한 로그 밀도의 기울기를 근사해 모델이 데이터를 더 잘 설명할 수 있도록 한다. 



## 1.4. Justification of the Training Objective
#### - Variational Lower Bound
전진과정을 추론 과정에 대해 고정된 근사 사후분포로 볼 수 있다면, 변분 하한을 이용해 주변 로그 가능도에 대해 다음과 같은 식을 유도할 수 있다. 

$$
\mathbb{E}_{\mathbf{x}, \mathbf{y}_0} \log p_{\theta} (\mathbf{y}_0 | \mathbf{x}) \ge \mathbb{E}_{\mathbf{x}, \mathbf{y}_0} \mathbb{E}_{q(\mathbf{y}_{1:T} | \mathbf{y}_0)} [ \log p(\mathbf{y}_T) + \sum_{t \ge 1} \log \frac{p_{\theta} (\mathbf{y}_{t-1} | \mathbf{y}_t, \mathbf{x})}{q(\mathbf{y}_t | \mathbf{y}_{t-1})}]
$$

그리고 특정한 추론 과정의 파라미터화에 따라 변분하한에 음수를 취해 다음과 같이 각 시간 단계에서 단순화된 손실 함수로 표현할 수 있다.

$$
\mathbb{E}_{\mathbf{x}, \mathbf{y}_0, \mathbf{\epsilon}} \sum_{t=1}^T \frac{1}{T} || \mathbf{\epsilon} - \epsilon_{\theta} (\mathbf{x}, \sqrt{\gamma_t}\mathbf{y}_0 + \sqrt{1-\gamma_t} \epsilon, \gamma_t )||_2^2
$$

복잡한 변분 하한을 최적화하는 대신, 이를 단순화하여 각 시간 단계별로 가중치를 적용한 손실 함수로 표현할 수 있고 모델을 더 효율적으로 학습 가능하다. 

# 참고
https://kimjy99.github.io/%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0/sr3/