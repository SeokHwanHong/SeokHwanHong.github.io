---
layout: single        # 문서 형식
title: Imgae Super-Resolution via Iterative Refinement (2021) # 제목
categories: Super-Resolution    # 카테고리
tag: [DL, Image, Generative, Diffusion]
author_profile: false # 홈페이지 프로필이 다른 페이지에도 뜨는지 여부
sidebar:              # 페이지 왼쪽에 카테고리 지정
    nav: "counts"       # sidebar의 주소 지정
#search: false # 블로그 내 검색 비활성화
use_math: true
---
# Keywords
Diffusion, Refinement, Super-Resolution, Deep Generative Model



# 1. Conditional Denoising Diffusion Model
#### - Notation

$\mathbf{x}$ : source image

$\mathbf{y} \in \mathbb{R}^d$ : target image 

$\mathbf{y}_T \sim \mathcal{N}(\mathbf{0}, \mathbf{I}) $ : pure noise image

$\mathcal{D} = \left{ \mathbf{x}_i, \mathbf{y}_i \right}_{i=1}^N \sim p(\mathbf{x}, \mathbf{y})$ : 미지의 분포에 대한 input-output 짝

$$p(\mathbf{y} \vert \mathbf{x})$$ : 일대다 mapping을 가지는 조건부 분포



#### - Conditional DDPM

<p align="center">
  <a href="#">
    <img src="/images/SR3/figure2.jpg" height="150" />
  </a>
  <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  <b>[ Figure 1 : Diffusion Processs ]</b> 
</p>

1. 정제 단계 $T$ 에 대해 목표 이미지 $$\mathbf{y}_0$$ 를 생성 

2. pure noise image $$\mathbf{y}_T \sim \mathcal{\mathbf{0}, \mathbf{I}}$$ 를 생성  

3. 모델이 결과물을 반복적으로 정제해 $$(\mathbf{y_{T-1}}, \mathbf{y_{T-2}}, ... , \mathbf{y_{0}})$$ 를 획득

4. $$\mathbf{y}_0 \sim p(\mathbf{y} \vert \mathbf{x})$$ 를 얻기 위해 조건부 분포 $$p_{\theta} (\mathbf{y}_{t-1} \vert \mathbf{y}_t, \mathbf{x})$$ 를 학습

forward diffusion process $$q(\mathbf{y}_t \vert \mathbf{y}_{t-1})$$ : 고정된 Markov chain을 통해 결과물에 점진적으로 Gaussian noise를 추가하는 과정



#### - Goal
$$\mathbf{x}$$ 에서 $$\mathbf{y}$$ 로 이미지를 정제하는 stochastic 반복 과정을 통해 $$p(\mathbf{y} \vert \mathbf{x})$$ 로 근사되는 모수적인 근사분포를 학습하는 것이 목표다. 즉, $$\mathbf{x}$$ 가 조건부로 주어졌을 때 역 Markov chain 을 통해 이미지를 정제함으로써 Gaussian diffusion 과정을 역방향으로 진행하는 것이다.



#### - Langevin Dynamics
확률적 샘플링 기법 중 하나로, 모델이 데이터의 잠재적인 확률 밀도 함수를 알고 있거나 이를 추정하기 위해 사용한다. 이 과정에서 데이터를 더 잘 설명가능한 분포를 탐색하는 방식이다. 기본 수식은 다음과 같다.

$$
\begin{split}
    x_{t+1} = x_t + \epsilon \nabla_x \log p(x_t) + \sqrt{2 \epsilon} z_t
\end{split}
$$

$\epsilon$ : step size

$\nabla_x \log p(x_t)$ : 로그 밀도함수의 기울기

$z_t$ : Gaussian Noise

이는 주로 확률적 최적화(local optima 에서 탈출), 복잡한 고차원 분포에서의 샘플링, 확률적 추론 등에 응용이 가능하다. 



## 1.1. Gaussian Diffusion Process
#### - Forward Process

$$
\begin{split}
    q(\mathbf{y}_{1:T} \vert \mathbf{y}_0) &= \prod_{t=1}^T q(\mathbf{y}_t \vert \mathbf{y}_{t-1}), \\
    q(\mathbf{y}_t \vert \mathbf{y}_{t-1}) &= \mathcal{N}(\mathbf{y}_t \vert \sqrt{\alpha_t} \mathbf{y}_{t-1}, (1-\alpha_t) \mathbf{I}), 
\end{split}
$$

$\alpha_{1:T} \in (0,1)$ : scalere parameter, 각 반복에서 노이즈의 분산을 결정, $t$ 가 무한대로 갈 때 분산을 제한



#### - Characterization
**1. $$\mathbf{y}_t$ 와 $\mathbf{y}_0$$ 사이에 존재하는 모든 중간 과정을 고려하지않고, 중간 단계에서 적분**

$$
\begin{split}
    q(\mathbf{y}_t \vert \mathbf{y}_0) = \mathcal{N}(\mathbf{y}_t \vert \sqrt{\gamma_t} \mathbf{y}_0, (1-\gamma_t) \mathbf{I})
\begin{split}
$$

여기서 $\gamma_t = \prod_{i=1}^t \alpha_i$

**2. 사후분포 유도**

$$
\begin{split}
    q(\mathbf{y}_{t-1} \vert \mathbf{y}_0, \mathbf{y}_t) &= \mathcal{N}(\mathbf{y}_{t-1} \vert \mathbf{\mu}, \sigma^2 \mathbf{I}) \\
    \mathbf{\mu} &= \frac{\sqrt{\gamma_{t-1}}(1-\alpha_t)}{1-\gamma_t} \mathbf{y}_0 + \frac{\sqrt{\alpha_t}(1-\gamma_{t-1})}{1-\gamma_t} \mathbf{y}_t \\
    \sigma^2 &= \frac{(1-\gamma_{t-1})(1-\alpha_t)}{1-\gamma_t}
\end{split}
$$

사후분포는 역과정을 parameterizing 할 때와 역과정에서 데이터의 로그 가능도에 대한 변분 하한을 계산할 때 도움이 된다.



## 1.2. Optimizing the Denosing Model
입력값으로 source image $$\mathbf{x}$$ 와 nosiy target image $$\tilde{\mathbf{y}}$$ 를 받는 denosing 신경망 모형 $$f_{\theta}$$ 를 최적화하는 것과 노이즈가 없는 깔끔한 이미지 $$\mathbf{y_0}$$ 를 복원하는 것이 목표다. 여기서 nosiy target image $$\tilde{\mathbf{y}}$$ 는 다음과 같다.

$$
\begin{split}
    \tilde{\mathbf{y}} = \sqrt{\gamma} \mathbf{y}_0 + \sqrt{1-\gamma} \mathbf{\epsilon}, \qquad \mathbf{\epsilon} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})
\end{split}
$$

그리고 각각의 목표에 대한 알고리즘은 다음과 같다.

<p align="center">
  <a href="#">
    <img src="/images/SR3/algorithm1.jpg" height="150" />
  </a>
  <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  <b>[ Algorithm 1 : Training a Denoising Model ]</b> 
</p>
<p align="center">
  <a href="#">
    <img src="/images/SR3/algorithm2.jpg" height="150" />
  </a>
  <br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  <b>[ Algorithm 2 : Inference in T Iterative Refinement Steps ]</b> 
</p>


위 알고리즘에서 denoising model $$f_{theta}$$ 는 $$\mathbf{x}, \mathbf{y}, \gamma$$ 를 받는데, 입력값을 노이즈 $$\gamma$$ 의 분산에 대한 충분통계량으로 받고 nosie vector $$\mathbf{\epsilon}$$ 으로 예측하도록 훈련된다. 



#### - Objective Function

$$
\begin{split}
    \mathbb{E}_{(\mathbf{x}, \mathbf{y})}\mathbb{E}_{(\mathbf{\epsilon}, \gamma)} \Vert f_{\theta}(\mathbf{x}, \underbrace{\sqrt{\gamma} \mathbf{y}_0 + \sqrt{1-\gamma} \mathbf{\epsilon}}_{\tilde{\mathbf{y}}}, \gamma) - \mathbf{\epsilon} \Vert^p_p \\
    \text{where} \mathbf{\epsilon} \sim \mathcal{N(\mathbf{0}, \mathbf{I})}, \; (\mathbf{x}, \mathbf{y}) \sim \mathcal{D}, \; p \in \{1,2\}, \: \gamma \sim p(\gamma)
\end{split}
$$

이 때 $p(\gamma)$ 는 모델과 생성되는 이미지의 품질에 많은 영향을 준다. 



## 1.3. Inference via Iterative Refinement
#### - Reverse Markovian Process

$$
\begin{split}
    p_{\theta} (\mathbf{y}_{0:T} \vert \mathbf{x}) &= p(\mathbf{y}_T) \prod_{t=1}^T p_{\theta}(\mathbf{y}_{t-1} \vert \mathbf{y}_T, \mathbf{x}) \\
    p(\mathbf{y}_T) &= \mathcal{N}(\mathbf{y}_T \vert \mathbf{0}, \mathbf{I}) \\
    p_{\theta}(\mathbf{y}_{t-1} \vert \mathbf{y}_t, \mathbf{x}) &= \mathcal{N}(\mathbf{y}_{t-1} \vert \mu_{\theta} (\mathbf{x}, \mathbf{y}_t, \gamma_t), \sigma_t^2 \mathbf{I})
\end{split}
$$

동일한 Gaussian 조건부 분포인 $$p_{\theta}(\mathbf{y}_{t-1} \vert \mathbf{y}_t, \mathbf{x})$$ 의 관점에서 추론을 진행한다. 만약 $$\alpha_{1:T} \approx 1$$ 이면 $$p_{\theta}(\mathbf{y}_{t-1} \vert \mathbf{y}_t, \mathbf{x})$$ 은 정규분포로 근사한다. 반면에 $$1-\gamma_t$$ 가 충분히 커야 사전분포 $$\mathbf{y}_{T}$$ 가 사전분포 $$p(\mathbf{y}_T) = \mathcal{N}(\mathbf{y}_{T} \vert \mathbf{0}, \mathbf{I})$$ 로 근사할 수 있다.



#### - Rearrangement 
**1. $$\hat{\mathbf{y}}_0$$**

1.2 의 $$\tilde{\mathbf{y}}$$ 를 이용해 $$\hat{\mathbf{y}}_0$$ 를 정리하면 다음과 같다.

$$
\begin{split}
    \hat{\mathbf{y}}_0 = \frac{1}{\sqrt{\gamma_t}} (\mathbf{y}_t - \sqrt{1-\gamma_t} f_{\theta} (\mathbf{x}, \mathbf{y}_t, \gamma_t))
\end{split}
$$


**2. mean of $p_{\theta}(\mathbf{y}_{t-1} \vert \mathbf{y}_t, \mathbf{x})$**

Rearaangement 1의 식을 사후분포 $$q(\mathbf{y}_{t-1} | \mathbf{y}_0, \mathbf{y}_t)$$ 에 대입하면 다음과 같이 정리할 수 있다.

$$
\begin{split}
    \mu_{\theta} (\mathbf{x}, \mathbf{y}_t, \gamma_t) = \frac{1}{\sqrt{\alpha_t}} (\mathbf{y}_t - \frac{1-\alpha_t}{\sqrt{1- \gamma_t}} f_{\theta}(\mathbf{x}, \mathbf{y}_t, \gamma_t))
\end{split}
$$

반면에 분산은 $1-\alpha_t$ 로 유도할 수 있다. 


**3. $$\mathbf{y}_{t-1}$$**

Rearrangment 1번과 2번을 이용해 각 반복에서 $$\mathbf{y}_{t-1}$$ 을 다음과 같은 형태로 사용할 수 있다.

$$
\begin{split}
    \mathbf{y}_{t-1} \leftarrow \frac{1}{\sqrt{\alpha_t}} (\mathbf{y}_t - \frac{1-\alpha_t}{\sqrt{1-\gamma_t}} f_{\theta}(\mathbf{x}, \mathbf{y}_t, \gamma_t)) + \sqrt{1-\alpha_t}\epsilon_t
\end{split}
$$

여기서 $$f_{\theta}$$ 가 주어진 데이터에 대한 로그 밀도의 기울기를 근사해 모델이 데이터를 더 잘 설명할 수 있도록 한다. 




## 1.4. Justification of the Training Objective
#### - Variational Lower Bound
전진과정을 추론 과정에 대해 고정된 근사 사후분포로 볼 수 있다면, 변분 하한을 이용해 주변 로그 가능도에 대해 다음과 같은 식을 유도할 수 있다. 

$$
\begin{split}
    \mathbb{E}_{\mathbf{x}, \mathbf{y}_0} \log p_{\theta} (\mathbf{y}_0 \vert \mathbf{x}) \ge \mathbb{E}_{\mathbf{x}, \mathbf{y}_0} \mathbb{E}_{q(\mathbf{y}_{1:T} \vert \mathbf{y}_0)} [ \log p(\mathbf{y}_T) + \sum_{t \ge 1} \log \frac{p_{\theta} (\mathbf{y}_{t-1} \vert \mathbf{y}_t, \mathbf{x})}{q(\mathbf{y}_t \vert \mathbf{y}_{t-1})}]
\end{split}
$$

그리고 특정한 추론 과정의 파라미터화에 따라 변분하한에 음수를 취해 다음과 같이 각 시간 단계에서 단순화된 손실 함수로 표현할 수 있다.

$$
\begin{split}
    \mathbb{E}_{\mathbf{x}, \mathbf{y}_0, \mathbf{\epsilon}} \sum_{t=1}^T \frac{1}{T} \Vert \mathbf{\epsilon} - \epsilon_{\theta} (\mathbf{x}, \sqrt{\gamma_t}\mathbf{y}_0 + \sqrt{1-\gamma_t} \epsilon, \gamma_t ) \Vert^2_2
\end{split}
$$

복잡한 변분 하한을 최적화하는 대신, 이를 단순화하여 각 시간 단계별로 가중치를 적용한 손실 함수로 표현할 수 있고 모델을 더 효율적으로 학습 가능하다. 

# 참고
https://kimjy99.github.io/%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0/sr3/