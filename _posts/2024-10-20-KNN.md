---
layout: single        # 문서 형식
title: K - Neaerest Neighborhood  # 제목
categories: Machine Learning    # 카테고리
tag: [ML, Statistics, Classification]
toc: true             # 글 목차
toc_sticky : true
toc_label: 목차
author_profile: false # 홈페이지 프로필이 다른 페이지에도 뜨는지 여부
sidebar:              # 페이지 왼쪽에 카테고리 지정
    nav: "docs"       # sidebar의 주소 지정
#search: false # 블로그 내 검색 비활성화
use_math: true
---
# Keywords
Machine Learning, Statistics, Classification, Supervised Learning



# 1. Definition
KNN (K - Neareast Neighborhood) 은 근접한 데이터 포인트끼리 군집을 형성하는 알고리즘이다. 이는 거리가 가까운 데이터 포인트끼리 비슷한 특성을 가질 것이라는 가정에 기반한다. 새로운 데이터 포인트의 레이블을 예측할 때, 미리 학습된 가중치나 모델이 없는 대신 훈련 데이터 전체를 참조해 K 개의 가장 가까운 이웃을 탐색해 그들 간 레이블을 바탕으로 예측을 수행한다.



# 2. Algorithm
1. Setting "K"
주변 이웃의 수 "K" 를 설정한다. K 값이 너무 작으면 과적합이 발생할 수 있고, 반대로 너무 크면 과소적합이 발생할 수 있다.

2. Distance 
새로운 데이터 $x_i$ 에 대해 훈련 데이터의 모든 데이터 포인트와의 거리를 계산한다. 주로 유클리디안 거리, 맨해튼 거리 등 사용한다.

3. Choose Neighborhood
거리를 계산한 후, $x_i$ 와 가장 가까운 K 개의 이웃을 선택한다.

4. Voting
가장 가까운 이웃 K 개를 다수결 투표로 가장 많이 속한 클래스를 예측한다.



# 3. Advantages & Disadvantages of KNN
#### - Advantages
1. 사전 학습이 필요 없고 새로운 데이터가 올때마다 연산을 수행하는 직관적 특성
2. 비선형 데이터 처리 가능
3. 다양한 문제에 적용 가능

#### - Disadvantages
1. 모든 데이터들에 대해 계산을 해야하기 때문에 연산량이 많음
2. 스케일 및 노이즈에 민감



