---
layout: single        # 문서 형식
title: Very Deep Convolutional Networks for Large-Scale Image Recognition (2015)       # 제목
categories: CNN    # 카테고리
tag: [DL, CNN]
toc: true             # 글 목차
toc_sticky : true     # toc 고정
toc_label: 목차       # toc 이름 설정
author_profiel: false # 홈페이지 프로필이 다른 페이지에도 뜨는지 여부
sidebar:              # 페이지 왼쪽에 카테고리 지정
    nav: "docs"       # sidebar의 주소 지정
#search: false # 블로그 내 검색 비활성화
use_math: true
---
# Keywords
CNN, DNN

# 1. Introduction 
CNN 이 이미지와 비디오 등 computer vision task에서 좋은 성과들을 내고있다. scaling, window size, stride, padding, depth 등을 조절해 모형의 성능을 확인하고 CNN 구조를 더 효율적으로 구성할 수 있는지 탐색하고자 한다. 

# 2. CNN Configurations
## 2.1. Architecture

#### - Train settings
input : $224 \times 224$ RGB images
preprocessing : 각 픽셀에 채널별(RGB) 평균으로 대체
filter size : $3 \times 3$ (가장 작은 filter 크기) -> $1\times 1$ 은 선형 변환
stride : 1 픽셀로 고정
padding : $3 \times 3 $ 에 padding = 1 추가 (전체 크기 $5 \times 5$)
spatial pooling : $2 \times 2$ max-pooling, stride = 2

#### - Stacks of Covolutional layers
첫 번째와 두 번째 층은 4096, 세 번째 층은 1000 channel로 구성. 마지막 층은 soft-max 함수로 구성

## 2.2. Configurations
본 논문에서 제안한 모형들은 다음과 같다. 

<figure style="text-align: center; display: inline-block; width: 100%;">
    <img src = "/images/VGG/Table1.jpg" height = 500>    
    <figcaption style="display: block; width: 100%; text-align: center;">[ Table 1 : CNN Configuration ]</figcaption>
</figure>

A에서 E로 갈수록 층을 추가해 모형이 깊이가 깊어진다. 

<figure style="text-align: center; display: inline-block; width: 100%;">
    <img src = "/images/VGG/Table2.jpg" height = 75>    
    <figcaption style="display: block; width: 100%; text-align: center;">[ Table 2 : Number of Parameters for each Configuration ]</figcaption>
</figure>

층이 추가되어 모수가 증가하는 것 이외에는 모수가 증가하지 않도록 구성하였다.

## 2.3. Discussions 
#### - Main Idea
1. 전체 구조에 stride 가 1인 $3 \times 3$ filter를 사용해 모든 픽셀이 합성되도록 구성
$ \rightarrow n \times n$ 대신 $3 \times 3$ filter를 사용함으로써 filter size에 대한 영향을 배제(image size 축소가 빠르게 이루어지기 때문), 오직 depth가 어떤 영향을 미치는지 확인

2. parameter 수 감소
$ \rightarrow 7 \times 7$ 이미지를 각각 $3 \times 3$ filter를 3번 통과한 것과 $7 \times 7$ 을 한번 통과시킬 때 필요한 parameter 수는 $3^3 \times C^2 = 27 C^2, 7^2 \times C = 49 C^2$ 이므로 $3 \times 3$ filter를 통과시키는 것이 더 효율적이다. 이를 그림으로 표현하면 다음과 같다

<figure style="text-align: center; display: inline-block; width: 100%;">
    <img src = "/images/VGG/idea2.jpg" height = 300>    
    <figcaption style="display: block; width: 100%; text-align: center;">[ Figure 1 : Main Idea 2 ]</figcaption>
</figure>

3. $1 \times 1 $ filter 사용 이유
합성곱 층에 대한 receptive field 의 영향없이 결정함수의 비선형성을 증가시키기 위해 사용


## 2.4. VGG 16 (Configuration "C")
<figure style="text-align: center; display: inline-block; width: 100%;">
    <img src = "/images/VGG/architecture.jpg" height = 350>    
    <figcaption style="display: block; width: 100%; text-align: center;">[ Figure 1 : Architecture of Configuration "C" ]</figcaption>
</figure>



# 참고
https://deep-learning-study.tistory.com/529
https://medium.com/@msmapark2/vgg16-%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0-very-deep-convolutional-networks-for-large-scale-image-recognition-6f748235242a
https://neurohive.io/en/popular-networks/vgg16/